|   No. |   analysis_result | title | authors | abstract | link |
|------:|:------------------|:------|:--------|:---------|:-----|
|     1 | {"pass_filter":false,"exclude_reason":"single-modality (only image)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality (only image)"} | SUB: Benchmarking CBM Generalization via Synthetic Attribute   Substitutions | Jessica Bader, Leander Girrbach, Stephan Alaniz, Zeynep Akata | Concept Bottleneck Models (CBMs) and other concept-based interpretable models show great promise for making AI applications more transparent, which is essential in fields like medicine. Despite their success, we demonstrate that CBMs struggle to reliably identify the correct concepts under distribution shifts. To assess the robustness of CBMs to concept variations, we introduce SUB: a fine-grained image and concept benchmark containing 38,400 synthetic images based on the CUB dataset. To create SUB, we select a CUB subset of 33 bird classes and 45 concepts to generate images which substitute a specific concept, such as wing color or belly pattern. We introduce a novel Tied Diffusion Guidance (TDG) method to precisely control generated images, where noise sharing for two parallel denoising processes ensures that both the correct bird class and the correct attribute are generated. This novel benchmark enables rigorous evaluation of CBMs and similar interpretable models, contributing to the development of more robust methods. Our code is available at https://github.com/ExplainableML/sub and the dataset at http://huggingface.co/datasets/Jessica-bader/SUB. | http://arxiv.org/abs/2507.23784v1 |
|     2 | {"pass_filter":false,"exclude_reason":"single-modality mesh generation","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality mesh generation"} | XSpecMesh: Quality-Preserving Auto-Regressive Mesh Generation   Acceleration via Multi-Head Speculative Decoding | Dian Chen, Yansong Qu, Xinyang Li, Ming Li, Shengchuan Zhang | Current auto-regressive models can generate high-quality, topologically precise meshes; however, they necessitate thousands-or even tens of thousands-of next-token predictions during inference, resulting in substantial latency. We introduce XSpecMesh, a quality-preserving acceleration method for auto-regressive mesh generation models. XSpecMesh employs a lightweight, multi-head speculative decoding scheme to predict multiple tokens in parallel within a single forward pass, thereby accelerating inference. We further propose a verification and resampling strategy: the backbone model verifies each predicted token and resamples any tokens that do not meet the quality criteria. In addition, we propose a distillation strategy that trains the lightweight decoding heads by distilling from the backbone model, encouraging their prediction distributions to align and improving the success rate of speculative predictions. Extensive experiments demonstrate that our method achieves a 1.7x speedup without sacrificing generation quality. Our code will be released. | http://arxiv.org/abs/2507.23777v1 |
|     3 | {"pass_filter":false,"exclude_reason":"single-modality (text-only via LLM)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality text-only (LLM-based world model without other modalities)"} | SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning   Architecture with LLM-Based World Model | Mingkai Deng, Jinyu Hou, Yilin Shen, Hongxia Jin, Graham Neubig, Zhiting Hu, Eric Xing | AI agents built on large language models (LLMs) hold enormous promise, but current practice focuses on a one-task-one-agent approach, which not only falls short of scalability and generality, but also suffers from the fundamental limitations of autoregressive LLMs. On the other hand, humans are general agents who reason by mentally simulating the outcomes of their actions and plans. Moving towards a more general and powerful AI agent, we introduce SimuRA, a goal-oriented architecture for generalized agentic reasoning. Based on a principled formulation of optimal agent in any environment, \modelname overcomes the limitations of autoregressive reasoning by introducing a world model for planning via simulation. The generalized world model is implemented using LLM, which can flexibly plan in a wide range of environments using the concept-rich latent space of natural language. Experiments on difficult web browsing tasks show that \modelname improves the success of flight search from 0\% to 32.2\%. World-model-based planning, in particular, shows consistent advantage of up to 124\% over autoregressive planning, demonstrating the advantage of world model simulation as a reasoning paradigm. We are excited about the possibility for training a single, general agent model based on LLMs that can act superintelligently in all environments. To start, we make SimuRA, a web-browsing agent built on \modelname with pretrained LLMs, available as a research demo for public testing. | http://arxiv.org/abs/2507.23773v1 |
|     4 | {"pass_filter":false,"exclude_reason":"insufficient core features (no multi-modal, large-scale, unified framework, or novel paradigm)","raw_score":0,"norm_score":0,"reason":"Excluded: insufficient core features (no multi-modal, large-scale, unified framework, or novel paradigm)"} | Consensus-Driven Active Model Selection | Justin Kay, Grant Van Horn, Subhransu Maji, Daniel Sheldon, Sara Beery | The widespread availability of off-the-shelf machine learning models poses a challenge: which model, of the many available candidates, should be chosen for a given data analysis task? This question of model selection is traditionally answered by collecting and annotating a validation dataset -- a costly and time-intensive process. We propose a method for active model selection, using predictions from candidate models to prioritize the labeling of test data points that efficiently differentiate the best candidate. Our method, CODA, performs consensus-driven active model selection by modeling relationships between classifiers, categories, and data points within a probabilistic framework. The framework uses the consensus and disagreement between models in the candidate pool to guide the label acquisition process, and Bayesian inference to update beliefs about which model is best as more information is collected. We validate our approach by curating a collection of 26 benchmark tasks capturing a range of model selection scenarios. CODA outperforms existing methods for active model selection significantly, reducing the annotation effort required to discover the best model by upwards of 70% compared to the previous state-of-the-art. Code and data are available at https://github.com/justinkay/coda. | http://arxiv.org/abs/2507.23771v1 |
|     5 | {"pass_filter":false,"exclude_reason":"single-modality (no visual/language/ etc.)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality (no visual/language/ etc.)"} | Formal Bayesian Transfer Learning via the Total Risk Prior | Nathan Wycoff, Ali Arab, Lisa O. Singh | In analyses with severe data-limitations, augmenting the target dataset with information from ancillary datasets in the application domain, called source datasets, can lead to significantly improved statistical procedures. However, existing methods for this transfer learning struggle to deal with situations where the source datasets are also limited and not guaranteed to be well-aligned with the target dataset. A typical strategy is to use the empirical loss minimizer on the source data as a prior mean for the target parameters, which places the estimation of source parameters outside of the Bayesian formalism. Our key conceptual contribution is to use a risk minimizer conditional on source parameters instead. This allows us to construct a single joint prior distribution for all parameters from the source datasets as well as the target dataset. As a consequence, we benefit from full Bayesian uncertainty quantification and can perform model averaging via Gibbs sampling over indicator variables governing the inclusion of each source dataset. We show how a particular instantiation of our prior leads to a Bayesian Lasso in a transformed coordinate system and discuss computational techniques to scale our approach to moderately sized datasets. We also demonstrate that recently proposed minimax-frequentist transfer learning techniques may be viewed as an approximate Maximum a Posteriori approach to our model. Finally, we demonstrate superior predictive performance relative to the frequentist baseline on a genetics application, especially when the source data are limited. | http://arxiv.org/abs/2507.23768v1 |
|     6 | {"pass_filter":false,"exclude_reason":"single-modality (only ticket pricing data, no other modalities)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality (only ticket pricing data, no other modalities)"} | Scaled Beta Models and Feature Dilution for Dynamic Ticket Pricing | Jonathan R. Landers | A novel approach is presented for identifying distinct signatures of performing acts in the secondary ticket resale market by analyzing dynamic pricing distributions. Using a newly curated, time series dataset from the SeatGeek API, we model ticket pricing distributions as scaled Beta distributions. This enables accurate parameter estimation from incomplete statistical data using a hybrid of quantile matching and the method of moments. Incorporating the estimated $\alpha$ and $\beta$ parameters into Random Forest classifiers significantly improves pairwise artist classification accuracy, demonstrating the unique economic signatures in event pricing data. Additionally, we provide theoretical and empirical evidence that incorporating zero-variance (constant-value) features into Random Forest models acts as an implicit regularizer, enhancing feature variety and robustness. This regularization promotes deeper, more varied trees in the ensemble, improving the bias-variance tradeoff and mitigating overfitting to dominant features. These findings are validated on both the new ticket pricing dataset and the standard UCI ML handwritten digits dataset. | http://arxiv.org/abs/2507.23767v1 |
|     7 | {"pass_filter":false,"exclude_reason":"single-modality active learning with mood/fatigue-aware Recommender System","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality and not involving multi-modal/large-scale/core features"} | Improving annotator selection in Active Learning using a mood and   fatigue-aware Recommender System | Diana Mortagua | This study centers on overcoming the challenge of selecting the best annotators for each query in Active Learning (AL), with the objective of minimizing misclassifications. AL recognizes the challenges related to cost and time when acquiring labeled data, and decreases the number of labeled data needed. Nevertheless, there is still the necessity to reduce annotation errors, aiming to be as efficient as possible, to achieve the expected accuracy faster. Most strategies for query-annotator pairs do not consider internal factors that affect productivity, such as mood, attention, motivation, and fatigue levels. This work addresses this gap in the existing literature, by not only considering how the internal factors influence annotators (mood and fatigue levels) but also presenting a new query-annotator pair strategy, using a Knowledge-Based Recommendation System (RS). The RS ranks the available annotators, allowing to choose one or more to label the queried instance using their past accuracy values, and their mood and fatigue levels, as well as information about the instance queried. This work bases itself on existing literature on mood and fatigue influence on human performance, simulating annotators in a realistic manner, and predicting their performance with the RS. The results show that considering past accuracy values, as well as mood and fatigue levels reduces the number of annotation errors made by the annotators, and the uncertainty of the model through its training, when compared to not using internal factors. Accuracy and F1-score values were also better in the proposed approach, despite not being as substantial as the aforementioned. The methodologies and findings presented in this study begin to explore the open challenge of human cognitive factors affecting AL. | http://arxiv.org/abs/2507.23756v1 |
|     8 | {"pass_filter":false,"exclude_reason":"single-modality (only text, no other modalities)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality (only text, no other modalities)"} | Rule2Text: Natural Language Explanation of Logical Rules in Knowledge   Graphs | Nasim Shirvani-Mahdavi, Devin Wingfield, Amin Ghasemi, Chengkai Li | Knowledge graphs (KGs) often contain sufficient information to support the inference of new facts. Identifying logical rules not only improves the completeness of a knowledge graph but also enables the detection of potential errors, reveals subtle data patterns, and enhances the overall capacity for reasoning and interpretation. However, the complexity of such rules, combined with the unique labeling conventions of each KG, can make them difficult for humans to understand. In this paper, we explore the potential of large language models to generate natural language explanations for logical rules. Specifically, we extract logical rules using the AMIE 3.5.1 rule discovery algorithm from the benchmark dataset FB15k-237 and two large-scale datasets, FB-CVT-REV and FB+CVT-REV. We examine various prompting strategies, including zero- and few-shot prompting, including variable entity types, and chain-of-thought reasoning. We conduct a comprehensive human evaluation of the generated explanations based on correctness, clarity, and hallucination, and also assess the use of large language models as automatic judges. Our results demonstrate promising performance in terms of explanation correctness and clarity, although several challenges remain for future research. All scripts and data used in this study are publicly available at https://github.com/idirlab/KGRule2NL}{https://github.com/idirlab/KGRule2NL. | http://arxiv.org/abs/2507.23740v1 |
|     9 | {"pass_filter":true,"exclude_reason":"","core_features":{"multi_modal":1,"large_scale":1,"unified_framework":1,"novel_paradigm":0},"plus_features":{"new_benchmark":0,"sota":0,"fusion_arch":0,"real_world_app":1,"reasoning_planning":0,"scaling_modalities":0,"open_source":0},"raw_score":7,"norm_score":7,"reason":"满足多模态（文本+图像）、大规模模型（LLM）和统一框架（混合规则与AI处理去标识化）三大核心特征，并面向医疗数据安全共享的真实应用场景。"} | DICOM De-Identification via Hybrid AI and Rule-Based Framework for   Scalable, Uncertainty-Aware Redaction | Kyle Naddeo, Nikolas Koutsoubis, Rahul Krish, Ghulam Rasool, Nidhal Bouaynaya, Tony OSullivan, Raj Krish | Access to medical imaging and associated text data has the potential to drive major advances in healthcare research and patient outcomes. However, the presence of Protected Health Information (PHI) and Personally Identifiable Information (PII) in Digital Imaging and Communications in Medicine (DICOM) files presents a significant barrier to the ethical and secure sharing of imaging datasets. This paper presents a hybrid de-identification framework developed by Impact Business Information Solutions (IBIS) that combines rule-based and AI-driven techniques, and rigorous uncertainty quantification for comprehensive PHI/PII removal from both metadata and pixel data.   Our approach begins with a two-tiered rule-based system targeting explicit and inferred metadata elements, further augmented by a large language model (LLM) fine-tuned for Named Entity Recognition (NER), and trained on a suite of synthetic datasets simulating realistic clinical PHI/PII. For pixel data, we employ an uncertainty-aware Faster R-CNN model to localize embedded text, extract candidate PHI via Optical Character Recognition (OCR), and apply the NER pipeline for final redaction. Crucially, uncertainty quantification provides confidence measures for AI-based detections to enhance automation reliability and enable informed human-in-the-loop verification to manage residual risks.   This uncertainty-aware deidentification framework achieves robust performance across benchmark datasets and regulatory standards, including DICOM, HIPAA, and TCIA compliance metrics. By combining scalable automation, uncertainty quantification, and rigorous quality assurance, our solution addresses critical challenges in medical data de-identification and supports the secure, ethical, and trustworthy release of imaging data for research. | http://arxiv.org/abs/2507.23736v1 |
|    10 | {"pass_filter":false,"exclude_reason":"single-modality anomaly detection","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality anomaly detection"} | Anomalous Samples for Few-Shot Anomaly Detection | Aymane Abdali, Bartosz Boguslawski, Lucas Drumetz, Vincent Gripon | Several anomaly detection and classification methods rely on large amounts of non-anomalous or "normal" samples under the assump- tion that anomalous data is typically harder to acquire. This hypothesis becomes questionable in Few-Shot settings, where as little as one anno- tated sample can make a significant difference. In this paper, we tackle the question of utilizing anomalous samples in training a model for bi- nary anomaly classification. We propose a methodology that incorporates anomalous samples in a multi-score anomaly detection score leveraging recent Zero-Shot and memory-based techniques. We compare the utility of anomalous samples to that of regular samples and study the benefits and limitations of each. In addition, we propose an augmentation-based validation technique to optimize the aggregation of the different anomaly scores and demonstrate its effectiveness on popular industrial anomaly detection datasets. | http://arxiv.org/abs/2507.23712v1 |
|    11 | {"pass_filter":true,"exclude_reason":"","core_features":{"multi_modal":1,"large_scale":0,"unified_framework":1,"novel_paradigm":0},"plus_features":{"new_benchmark":0,"sota":1,"fusion_arch":0,"real_world_app":1,"reasoning_planning":0,"scaling_modalities":0,"open_source":0},"raw_score":6,"norm_score":6,"reason":"满足多模态与统一框架核心特征，并在真实应用和SOTA性能上表现突出。"} | villa-X: Enhancing Latent Action Modeling in Vision-Language-Action   Models | Xiaoyu Chen, Hangxing Wei, Pushi Zhang, Chuheng Zhang, Kaixin Wang, Yanjiang Guo, Rushuai Yang, Yucen Wang, Xinquan Xiao, Li Zhao, Jianyu Chen, Jiang Bian | Visual-Language-Action (VLA) models have emerged as a popular paradigm for learning robot manipulation policies that can follow language instructions and generalize to novel scenarios. Recent work has begun to explore the incorporation of latent actions, an abstract representation of visual change between two frames, into VLA pre-training. In this paper, we introduce villa-X, a novel Visual-Language-Latent-Action (ViLLA) framework that advances latent action modeling for learning generalizable robot manipulation policies. Our approach improves both how latent actions are learned and how they are incorporated into VLA pre-training. Together, these contributions enable villa-X to achieve superior performance across simulated environments including SIMPLER and LIBERO, as well as on two real-world robot setups including gripper and dexterous hand manipulation. We believe the ViLLA paradigm holds significant promise, and that our villa-X provides a strong foundation for future research. | http://arxiv.org/abs/2507.23682v1 |
|    12 | {"pass_filter":false,"exclude_reason":"single-modality microbiome data (no visual modality)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality microbiome data (no visual modality)"} | DepMicroDiff: Diffusion-Based Dependency-Aware Multimodal Imputation for   Microbiome Data | Rabeya Tus Sadia, Qiang Cheng | Microbiome data analysis is essential for understanding host health and disease, yet its inherent sparsity and noise pose major challenges for accurate imputation, hindering downstream tasks such as biomarker discovery. Existing imputation methods, including recent diffusion-based models, often fail to capture the complex interdependencies between microbial taxa and overlook contextual metadata that can inform imputation. We introduce DepMicroDiff, a novel framework that combines diffusion-based generative modeling with a Dependency-Aware Transformer (DAT) to explicitly capture both mutual pairwise dependencies and autoregressive relationships. DepMicroDiff is further enhanced by VAE-based pretraining across diverse cancer datasets and conditioning on patient metadata encoded via a large language model (LLM). Experiments on TCGA microbiome datasets show that DepMicroDiff substantially outperforms state-of-the-art baselines, achieving higher Pearson correlation (up to 0.712), cosine similarity (up to 0.812), and lower RMSE and MAE across multiple cancer types, demonstrating its robustness and generalizability for microbiome imputation. | http://arxiv.org/abs/2507.23676v1 |
|    13 | {"pass_filter":false,"exclude_reason":"single-modality reinforcement learning","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality reinforcement learning"} | One-Step Flow Policy Mirror Descent | Tianyi Chen, Haitong Ma, Na Li, Kai Wang, Bo Dai | Diffusion policies have achieved great success in online reinforcement learning (RL) due to their strong expressive capacity. However, the inference of diffusion policy models relies on a slow iterative sampling process, which limits their responsiveness. To overcome this limitation, we propose Flow Policy Mirror Descent (FPMD), an online RL algorithm that enables 1-step sampling during policy inference. Our approach exploits a theoretical connection between the distribution variance and the discretization error of single-step sampling in straight interpolation flow matching models, and requires no extra distillation or consistency training. We present two algorithm variants based on flow policy and MeanFlow policy parametrizations, respectively. Extensive empirical evaluations on MuJoCo benchmarks demonstrate that our algorithms show strong performance comparable to diffusion policy baselines while requiring hundreds of times fewer function evaluations during inference. | http://arxiv.org/abs/2507.23675v1 |
|    14 | {"pass_filter":false,"exclude_reason":"single-modality (only text, LLM)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality (only text, LLM)"} | TweakLLM: A Routing Architecture for Dynamic Tailoring of Cached   Responses | Muhammad Taha Cheema, Abeer Aamir, Khawaja Gul Muhammad, Naveed Anwar Bhatti, Ihsan Ayyub Qazi, Zafar Ayyub Qazi | Large Language Models (LLMs) process millions of queries daily, making efficient response caching a compelling optimization for reducing cost and latency. However, preserving relevance to user queries using this approach proves difficult due to the personalized nature of chatbot interactions and the limited accuracy of semantic similarity search. To address this, we present TweakLLM, a novel routing architecture that employs a lightweight LLM to dynamically adapt cached responses to incoming prompts. Through comprehensive evaluation, including user studies with side-by-side comparisons, satisfaction voting, as well as multi-agent LLM debates, we demonstrate that TweakLLM maintains response quality comparable to frontier models while significantly improving cache effectiveness. Our results across real-world datasets highlight TweakLLM as a scalable, resource-efficient caching solution for high-volume LLM deployments without compromising user experience. | http://arxiv.org/abs/2507.23674v1 |
|    15 | {"pass_filter":false,"exclude_reason":"core features < 2 (only multi_modal)","raw_score":0,"norm_score":0,"reason":"Excluded: core features < 2 (only multi_modal)"} | SAMSA: Segment Anything Model Enhanced with Spectral Angles for   Hyperspectral Interactive Medical Image Segmentation | Alfie Roddan, Tobias Czempiel, Chi Xu, Daniel S. Elson, Stamatia Giannarou | Hyperspectral imaging (HSI) provides rich spectral information for medical imaging, yet encounters significant challenges due to data limitations and hardware variations. We introduce SAMSA, a novel interactive segmentation framework that combines an RGB foundation model with spectral analysis. SAMSA efficiently utilizes user clicks to guide both RGB segmentation and spectral similarity computations. The method addresses key limitations in HSI segmentation through a unique spectral feature fusion strategy that operates independently of spectral band count and resolution. Performance evaluation on publicly available datasets has shown 81.0% 1-click and 93.4% 5-click DICE on a neurosurgical and 81.1% 1-click and 89.2% 5-click DICE on an intraoperative porcine hyperspectral dataset. Experimental results demonstrate SAMSA's effectiveness in few-shot and zero-shot learning scenarios and using minimal training examples. Our approach enables seamless integration of datasets with different spectral characteristics, providing a flexible framework for hyperspectral medical image analysis. | http://arxiv.org/abs/2507.23673v1 |
|    16 | {"pass_filter":false,"exclude_reason":"core features < 2","raw_score":0,"norm_score":0,"reason":"Excluded: core features < 2"} | SHAP-Guided Regularization in Machine Learning Models | Amal Saadallah | Feature attribution methods such as SHapley Additive exPlanations (SHAP) have become instrumental in understanding machine learning models, but their role in guiding model optimization remains underexplored. In this paper, we propose a SHAP-guided regularization framework that incorporates feature importance constraints into model training to enhance both predictive performance and interpretability. Our approach applies entropy-based penalties to encourage sparse, concentrated feature attributions while promoting stability across samples. The framework is applicable to both regression and classification tasks. Our first exploration started with investigating a tree-based model regularization using TreeSHAP. Through extensive experiments on benchmark regression and classification datasets, we demonstrate that our method improves generalization performance while ensuring robust and interpretable feature attributions. The proposed technique offers a novel, explainability-driven regularization approach, making machine learning models both more accurate and more reliable. | http://arxiv.org/abs/2507.23665v1 |
|    17 | {"pass_filter":false,"exclude_reason":"single-modality (visual/MRI data only)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality (visual/MRI data only)"} | OptiGradTrust: Byzantine-Robust Federated Learning with Multi-Feature   Gradient Analysis and Reinforcement Learning-Based Trust Weighting | Mohammad Karami, Fatemeh Ghassemi, Hamed Kebriaei, Hamid Azadegan | Federated Learning (FL) enables collaborative model training across distributed medical institutions while preserving patient privacy, but remains vulnerable to Byzantine attacks and statistical heterogeneity. We present OptiGradTrust, a comprehensive defense framework that evaluates gradient updates through a novel six-dimensional fingerprint including VAE reconstruction error, cosine similarity metrics, $L_2$ norm, sign-consistency ratio, and Monte Carlo Shapley value, which drive a hybrid RL-attention module for adaptive trust scoring. To address convergence challenges under data heterogeneity, we develop FedBN-Prox (FedBN-P), combining Federated Batch Normalization with proximal regularization for optimal accuracy-convergence trade-offs. Extensive evaluation across MNIST, CIFAR-10, and Alzheimer's MRI datasets under various Byzantine attack scenarios demonstrates significant improvements over state-of-the-art defenses, achieving up to +1.6 percentage points over FLGuard under non-IID conditions while maintaining robust performance against diverse attack patterns through our adaptive learning approach. | http://arxiv.org/abs/2507.23638v1 |
|    18 | {"pass_filter":false,"exclude_reason":"single-modality (pure text)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality (pure text)"} | On the Expressiveness of Softmax Attention: A Recurrent Neural Network   Perspective | Gabriel Mongaras, Eric C. Larson | Since its introduction, softmax attention has become the backbone of modern transformer architectures due to its expressiveness and scalability across a wide range of tasks. However, the main drawback of softmax attention is the quadratic memory requirement and computational complexity with respect to the sequence length. By replacing the softmax nonlinearity, linear attention and similar methods have been introduced to avoid the quadratic bottleneck of softmax attention. Despite these linear forms of attention being derived from the original softmax formulation, they typically lag in terms of downstream accuracy. While strong intuition of the softmax nonlinearity on the query and key inner product suggests that it has desirable properties compared to other nonlinearities, the question of why this discrepancy exists still remains unanswered. This work demonstrates that linear attention is an approximation of softmax attention by deriving the recurrent form of softmax attention. Using this form, each part of softmax attention can be described in the language of recurrent neural networks (RNNs). Describing softmax attention as an RNN allows for the ablation of the components of softmax attention to understand the importance of each part and how they interact. In this way, our work helps explain why softmax attention is more expressive than its counterparts. | http://arxiv.org/abs/2507.23632v1 |
|    19 | {"pass_filter":true,"exclude_reason":"","core_features":{"multi_modal":1,"large_scale":0,"unified_framework":1,"novel_paradigm":1},"plus_features":{"new_benchmark":0,"sota":1,"fusion_arch":1,"real_world_app":0,"reasoning_planning":0,"scaling_modalities":0,"open_source":0},"raw_score":8,"norm_score":8,"reason":"满足多模态（文本-图像）、统一框架（多条件生成）及新颖范式（SVD分解与知识转移）三大核心特征，且在SOTA和融合架构创新上加分。"} | DivControl: Knowledge Diversion for Controllable Image Generation | Yucheng Xie, Fu Feng, Ruixiao Shi, Jing Wang, Yong Rui, Xin Geng | Diffusion models have advanced from text-to-image (T2I) to image-to-image (I2I) generation by incorporating structured inputs such as depth maps, enabling fine-grained spatial control. However, existing methods either train separate models for each condition or rely on unified architectures with entangled representations, resulting in poor generalization and high adaptation costs for novel conditions. To this end, we propose DivControl, a decomposable pretraining framework for unified controllable generation and efficient adaptation. DivControl factorizes ControlNet via SVD into basic components-pairs of singular vectors-which are disentangled into condition-agnostic learngenes and condition-specific tailors through knowledge diversion during multi-condition training. Knowledge diversion is implemented via a dynamic gate that performs soft routing over tailors based on the semantics of condition instructions, enabling zero-shot generalization and parameter-efficient adaptation to novel conditions. To further improve condition fidelity and training efficiency, we introduce a representation alignment loss that aligns condition embeddings with early diffusion features. Extensive experiments demonstrate that DivControl achieves state-of-the-art controllability with 36.4$\times$ less training cost, while simultaneously improving average performance on basic conditions. It also delivers strong zero-shot and few-shot performance on unseen conditions, demonstrating superior scalability, modularity, and transferability. | http://arxiv.org/abs/2507.23620v1 |
|    20 | {"pass_filter":false,"exclude_reason":"single-modality time series","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality time series"} | L-GTA: Latent Generative Modeling for Time Series Augmentation | Luis Roque, Carlos Soares, Vitor Cerqueira, Luis Torgo | Data augmentation is gaining importance across various aspects of time series analysis, from forecasting to classification and anomaly detection tasks. We introduce the Latent Generative Transformer Augmentation (L-GTA) model, a generative approach using a transformer-based variational recurrent autoencoder. This model uses controlled transformations within the latent space of the model to generate new time series that preserve the intrinsic properties of the original dataset. L-GTA enables the application of diverse transformations, ranging from simple jittering to magnitude warping, and combining these basic transformations to generate more complex synthetic time series datasets. Our evaluation of several real-world datasets demonstrates the ability of L-GTA to produce more reliable, consistent, and controllable augmented data. This translates into significant improvements in predictive accuracy and similarity measures compared to direct transformation methods. | http://arxiv.org/abs/2507.23615v1 |
|    21 | {"pass_filter":false,"exclude_reason":"single-modality (CT/MRI images only, no language/text)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality (CT/MRI images only, no language/text)"} | Consistent Point Matching | Halid Ziya Yerebakan, Gerardo Hermosillo Valadez | This study demonstrates that incorporating a consistency heuristic into the point-matching algorithm \cite{yerebakan2023hierarchical} improves robustness in matching anatomical locations across pairs of medical images. We validated our approach on diverse longitudinal internal and public datasets spanning CT and MRI modalities. Notably, it surpasses state-of-the-art results on the Deep Lesion Tracking dataset. Additionally, we show that the method effectively addresses landmark localization. The algorithm operates efficiently on standard CPU hardware and allows configurable trade-offs between speed and robustness. The method enables high-precision navigation between medical images without requiring a machine learning model or training data. | http://arxiv.org/abs/2507.23609v1 |
|    22 | {"pass_filter":false,"exclude_reason":"single-modality clinical NLP (only text, no visual)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality clinical NLP (only text, no visual)"} | Deep Learning-based Prediction of Clinical Trial Enrollment with   Uncertainty Estimates | Tien Huu Do, Antoine Masquelier, Nae Eoun Lee, Jonathan Crowther | Clinical trials are a systematic endeavor to assess the safety and efficacy of new drugs or treatments. Conducting such trials typically demands significant financial investment and meticulous planning, highlighting the need for accurate predictions of trial outcomes. Accurately predicting patient enrollment, a key factor in trial success, is one of the primary challenges during the planning phase. In this work, we propose a novel deep learning-based method to address this critical challenge. Our method, implemented as a neural network model, leverages pre-trained language models (PLMs) to capture the complexities and nuances of clinical documents, transforming them into expressive representations. These representations are then combined with encoded tabular features via an attention mechanism. To account for uncertainties in enrollment prediction, we enhance the model with a probabilistic layer based on the Gamma distribution, which enables range estimation. We apply the proposed model to predict clinical trial duration, assuming site-level enrollment follows a Poisson-Gamma process. We carry out extensive experiments on real-world clinical trial data, and show that the proposed method can effectively predict the number of patients enrolled at a number of sites for a given clinical trial, outperforming established baseline models. | http://arxiv.org/abs/2507.23607v1 |
|    23 | {"pass_filter":false,"exclude_reason":"insufficient core features (only 1 out of 4)","raw_score":0,"norm_score":0,"reason":"Excluded: insufficient core features (only 1 out of 4)"} | Hierarchical Message-Passing Policies for Multi-Agent Reinforcement   Learning | Tommaso Marzi, Cesare Alippi, Andrea Cini | Decentralized Multi-Agent Reinforcement Learning (MARL) methods allow for learning scalable multi-agent policies, but suffer from partial observability and induced non-stationarity. These challenges can be addressed by introducing mechanisms that facilitate coordination and high-level planning. Specifically, coordination and temporal abstraction can be achieved through communication (e.g., message passing) and Hierarchical Reinforcement Learning (HRL) approaches to decision-making. However, optimization issues limit the applicability of hierarchical policies to multi-agent systems. As such, the combination of these approaches has not been fully explored. To fill this void, we propose a novel and effective methodology for learning multi-agent hierarchies of message-passing policies. We adopt the feudal HRL framework and rely on a hierarchical graph structure for planning and coordination among agents. Agents at lower levels in the hierarchy receive goals from the upper levels and exchange messages with neighboring agents at the same level. To learn hierarchical multi-agent policies, we design a novel reward-assignment method based on training the lower-level policies to maximize the advantage function associated with the upper levels. Results on relevant benchmarks show that our method performs favorably compared to the state of the art. | http://arxiv.org/abs/2507.23604v1 |
|    24 | {"pass_filter":false,"exclude_reason":"single-modality signal unmixing","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality signal unmixing"} | EB-gMCR: Energy-Based Generative Modeling for Signal Unmixing and   Multivariate Curve Resolution | Yu-Tang Chang, Shih-Fang Chen | Signal unmixing analysis decomposes data into basic patterns and is widely applied in chemical and biological research. Multivariate curve resolution (MCR), a branch of signal unmixing, separates mixed chemical signals into base patterns (components) and their concentrations, playing a key role in understanding composition. Classical MCR is typically framed as matrix factorization (MF) and requires a user-specified component count, usually unknown in real data. As dataset size or component count increases, the scalability and reliability of MF-based MCR face significant challenges. This study reformulates MCR as a generative process (gMCR), and introduces an energy-based deep learning solver, EB-gMCR, that automatically discovers the smallest component set able to reconstruct the data faithfully. EB-gMCR starts from a large candidate pool (e.g., 1024 spectra) and employs a differentiable gating network to retain only active components while estimating their concentrations. On noisy synthetic datasets containing up to 256 latent sources, EB-gMCR maintained R^2 >= 0.98 and recovered the component count within 5% of the ground truth; at lower noise it achieved R^2 >= 0.99 with near exact component estimation. Additional chemical priors, such as non-negativity or nonlinear mixing, enter as simple plug-in functions, enabling adaptation to other instruments or domains without altering the core learning process. By uniting high-capacity generative modeling and hard component selection, EB-gMCR offers a practical route to large-scale signal unmixing analysis, including chemical library-driven scenarios. The source code is available at https://github.com/b05611038/ebgmcr_solver. | http://arxiv.org/abs/2507.23600v1 |
|    25 | {"pass_filter":false,"exclude_reason":"single-modality (graph not visual, only text and graph)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality (graph not visual, only text and graph)"} | GraphRAG-R1: Graph Retrieval-Augmented Generation with   Process-Constrained Reinforcement Learning | Chuanyue Yu, Kuo Zhao, Yuhan Li, Heng Chang, Mingjian Feng, Xiangzhe Jiang, Yufei Sun, Jia Li, Yuzhi Zhang, Jianxin Li, Ziwei Zhang | Graph Retrieval-Augmented Generation (GraphRAG) has shown great effectiveness in enhancing the reasoning abilities of LLMs by leveraging graph structures for knowledge representation and modeling complex real-world relationships. However, existing GraphRAG methods still face significant bottlenecks when handling complex problems that require multi-hop reasoning, as their query and retrieval phases are largely based on pre-defined heuristics and do not fully utilize the reasoning potentials of LLMs. To address this problem, we propose GraphRAG-R1, an adaptive GraphRAG framework by training LLMs with process-constrained outcome-based reinforcement learning (RL) to enhance the multi-hop reasoning ability. Our method can decompose complex problems, autonomously invoke retrieval tools to acquire necessary information, and perform effective reasoning. Specifically, we utilize a modified version of Group Relative Policy Optimization (GRPO) that supports rollout-with-thinking capability. Next, we design two process-constrained reward functions. To handle the shallow retrieval problem, we design a Progressive Retrieval Attenuation (PRA) reward to encourage essential retrievals. Then, to handle the over-thinking problem, we design Cost-Aware F1 (CAF) reward to balance the model performance with computational costs. We further design a phase-dependent training strategy, containing three training stages corresponding to cold start and these two rewards. Lastly, our method adopts a hybrid graph-textual retrieval to improve the reasoning capacity. Extensive experimental results demonstrate that GraphRAG-R1 boosts LLM capabilities in solving complex reasoning problems compared to state-of-the-art GraphRAG methods on both in-domain and out-of-domain datasets. Furthermore, our framework can be flexibly integrated with various existing retrieval methods, consistently delivering performance improvements. | http://arxiv.org/abs/2507.23581v1 |
|    26 | {"pass_filter":false,"exclude_reason":"single-modality feature selection algorithm","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality feature selection algorithm"} | Optimised Feature Subset Selection via Simulated Annealing | Fernando Martínez-García, Álvaro Rubio-García, Samuel Fernández-Lorenzo, Juan José García-Ripoll, Diego Porras | We introduce SA-FDR, a novel algorithm for $\ell_0$-norm feature selection that considers this task as a combinatorial optimisation problem and solves it by using simulated annealing to perform a global search over the space of feature subsets. The optimisation is guided by the Fisher discriminant ratio, which we use as a computationally efficient proxy for model quality in classification tasks. Our experiments, conducted on datasets with up to hundreds of thousands of samples and hundreds of features, demonstrate that SA-FDR consistently selects more compact feature subsets while achieving a high predictive accuracy. This ability to recover informative yet minimal sets of features stems from its capacity to capture inter-feature dependencies often missed by greedy optimisation approaches. As a result, SA-FDR provides a flexible and effective solution for designing interpretable models in high-dimensional settings, particularly when model sparsity, interpretability, and performance are crucial. | http://arxiv.org/abs/2507.23568v1 |
|    27 | {"pass_filter":false,"exclude_reason":"single-modality SNNs (no multi-modal integration)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality SNNs (no multi-modal integration)"} | Hardware-Aware Fine-Tuning of Spiking Q-Networks on the SpiNNaker2   Neuromorphic Platform | Sirine Arfa, Bernhard Vogginger, Christian Mayr | Spiking Neural Networks (SNNs) promise orders-of-magnitude lower power consumption and low-latency inference on neuromorphic hardware for a wide range of robotic tasks. In this work, we present an energy-efficient implementation of a reinforcement learning (RL) algorithm using quantized SNNs to solve two classical control tasks. The network is trained using the Q-learning algorithm, then fine-tuned and quantized to low-bit (8-bit) precision for embedded deployment on the SpiNNaker2 neuromorphic chip. To evaluate the comparative advantage of SpiNNaker2 over conventional computing platforms, we analyze inference latency, dynamic power consumption, and energy cost per inference for our SNN models, comparing performance against a GTX 1650 GPU baseline. Our results demonstrate SpiNNaker2's strong potential for scalable, low-energy neuromorphic computing, achieving up to 32x reduction in energy consumption. Inference latency remains on par with GPU-based execution, with improvements observed in certain task settings, reinforcing SpiNNaker2's viability for real-time neuromorphic control and making the neuromorphic approach a compelling direction for efficient deep Q-learning. | http://arxiv.org/abs/2507.23562v1 |
|    28 | {"pass_filter":false,"exclude_reason":"No core features (multi-modal, large_scale, unified_framework, novel_paradigm)","raw_score":0,"norm_score":0,"reason":"Excluded: No core features (multi-modal, large_scale, unified_framework, novel_paradigm)"} | Improved Algorithms for Kernel Matrix-Vector Multiplication Under   Sparsity Assumptions | Piotr Indyk, Michael Kapralov, Kshiteej Sheth, Tal Wagner | Motivated by the problem of fast processing of attention matrices, we study fast algorithms for computing matrix-vector products for asymmetric Gaussian Kernel matrices $K\in \mathbb{R}^{n\times n}$. $K$'s columns are indexed by a set of $n$ keys $k_1,k_2\ldots, k_n\in \mathbb{R}^d$, rows by a set of $n$ queries $q_1,q_2,\ldots,q_n\in \mathbb{R}^d $, and its $i,j$ entry is $K_{ij} = e^{-\ | q_i-k_j\ |
|    29 | {"pass_filter":false,"exclude_reason":"core features < 2 (only large_scale, lacks multi_modal/unified_framework/novel_paradigm)","raw_score":0,"norm_score":0,"reason":"Excluded: core features < 2 (only large_scale, lacks multi_modal/unified_framework/novel_paradigm)"} | From LLMs to Edge: Parameter-Efficient Fine-Tuning on Edge Devices | Georg Slamanig, Francesco Corti, Olga Saukh | Parameter-efficient fine-tuning (PEFT) methods reduce the computational costs of updating deep learning models by minimizing the number of additional parameters used to adapt a model to a down- stream task. While extensively researched in large language models (LLMs), their application to smaller models used on edge devices, such as convolutional neural networks, remains underexplored. This paper benchmarks and analyzes popular PEFT methods on convolutional architectures typically deployed in resource-constrained edge environments. We evaluate LoRA, DoRA, and GaLore for updating standard and depthwise convolutional architectures to handle distribution shifts and accommodate unseen classes. We utilize recently proposed PyTorch profilers to compare the updated model performance and computational costs of these PEFT methods with traditional fine-tuning approaches. With resource efficiency in mind, we investigate their update behavior across different rank dimensions. We find that the evaluated PEFT methods are only half as memory-efficient when applied to depthwise-separable convolution architectures, compared to their efficiency with LLMs. Conversely, when targeting convolu- tional architectures optimized for edge deployment, adapter-based PEFT methods can reduce floating point operations (FLOPs) during model updates by up to 95%. These insights offer valuable guidance for selecting PEFT methods based on hardware constraints, performance requirements, and application needs. Our code is online. | http://arxiv.org/abs/2507.23536v1 |
|    30 | {"pass_filter":false,"exclude_reason":"core_features不足（需≥2项，无multi_modal/large_scale等核心特征）","raw_score":0,"norm_score":0,"reason":"Excluded: core_features不足（需≥2项，无multi_modal/large_scale等核心特征）"} | Transparent AI: The Case for Interpretability and Explainability | Dhanesh Ramachandram, Himanshu Joshi, Judy Zhu, Dhari Gandhi, Lucas Hartman, Ananya Raval | As artificial intelligence systems increasingly inform high-stakes decisions across sectors, transparency has become foundational to responsible and trustworthy AI implementation. Leveraging our role as a leading institute in advancing AI research and enabling industry adoption, we present key insights and lessons learned from practical interpretability applications across diverse domains. This paper offers actionable strategies and implementation guidance tailored to organizations at varying stages of AI maturity, emphasizing the integration of interpretability as a core design principle rather than a retrospective add-on. | http://arxiv.org/abs/2507.23535v1 |
|    31 | {"pass_filter":false,"exclude_reason":"Insufficient core features (only 1 out of 4 required: only novel_paradigm is met)","raw_score":0,"norm_score":0,"reason":"Excluded: Insufficient core features (only 1 out of 4 required)"} | Continual Learning with Synthetic Boundary Experience Blending | Chih-Fan Hsu, Ming-Ching Chang, Wei-Chao Chen | Continual learning (CL) aims to address catastrophic forgetting in models trained sequentially on multiple tasks. While experience replay has shown promise, its effectiveness is often limited by the sparse distribution of stored key samples, leading to overly simplified decision boundaries. We hypothesize that introducing synthetic data near the decision boundary (Synthetic Boundary Data, or SBD) during training serves as an implicit regularizer, improving boundary stability and mitigating forgetting. To validate this hypothesis, we propose a novel training framework, {\bf Experience Blending}, which integrates knowledge from both stored key samples and synthetic, boundary-adjacent data. Experience blending consists of two core components: (1) a multivariate Differential Privacy (DP) noise mechanism that injects batch-wise noise into low-dimensional feature representations, generating SBD; and (2) an end-to-end training strategy that jointly leverages both stored key samples and SBD. Extensive experiments on CIFAR-10, CIFAR-100, and Tiny ImageNet demonstrate that our method outperforms nine CL baselines, achieving accuracy improvements of 10%, 6%, and 13%, respectively. | http://arxiv.org/abs/2507.23534v1 |
|    32 | {"pass_filter":true,"exclude_reason":"","core_features":{"multi_modal":1,"large_scale":1,"unified_framework":0,"novel_paradigm":1},"plus_features":{"new_benchmark":0,"sota":1,"fusion_arch":0,"real_world_app":1,"reasoning_planning":0,"scaling_modalities":0,"open_source":0},"raw_score":8,"norm_score":8,"reason":"满足多模态、大规模、新颖范式核心特征，在SOTA和真实世界应用方面表现突出。"} | H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation | Hongzhe Bi, Lingxuan Wu, Tianwei Lin, Hengkai Tan, Zhizhong Su, Hang Su, Jun Zhu | Imitation learning for robotic manipulation faces a fundamental challenge: the scarcity of large-scale, high-quality robot demonstration data. Recent robotic foundation models often pre-train on cross-embodiment robot datasets to increase data scale, while they face significant limitations as the diverse morphologies and action spaces across different robot embodiments make unified training challenging. In this paper, we present H-RDT (Human to Robotics Diffusion Transformer), a novel approach that leverages human manipulation data to enhance robot manipulation capabilities. Our key insight is that large-scale egocentric human manipulation videos with paired 3D hand pose annotations provide rich behavioral priors that capture natural manipulation strategies and can benefit robotic policy learning. We introduce a two-stage training paradigm: (1) pre-training on large-scale egocentric human manipulation data, and (2) cross-embodiment fine-tuning on robot-specific data with modular action encoders and decoders. Built on a diffusion transformer architecture with 2B parameters, H-RDT uses flow matching to model complex action distributions. Extensive evaluations encompassing both simulation and real-world experiments, single-task and multitask scenarios, as well as few-shot learning and robustness assessments, demonstrate that H-RDT outperforms training from scratch and existing state-of-the-art methods, including Pi0 and RDT, achieving significant improvements of 13.9% and 40.5% over training from scratch in simulation and real-world experiments, respectively. The results validate our core hypothesis that human manipulation data can serve as a powerful foundation for learning bimanual robotic manipulation policies. | http://arxiv.org/abs/2507.23523v1 |
|    33 | {"pass_filter":false,"exclude_reason":"纯理论无实证","raw_score":0,"norm_score":0,"reason":"Excluded: 纯理论无实证"} | Differentially Private Clipped-SGD: High-Probability Convergence with   Arbitrary Clipping Level | Saleh Vatan Khah, Savelii Chezhegov, Shahrokh Farahmand, Samuel Horváth, Eduard Gorbunov | Gradient clipping is a fundamental tool in Deep Learning, improving the high-probability convergence of stochastic first-order methods like SGD, AdaGrad, and Adam under heavy-tailed noise, which is common in training large language models. It is also a crucial component of Differential Privacy (DP) mechanisms. However, existing high-probability convergence analyses typically require the clipping threshold to increase with the number of optimization steps, which is incompatible with standard DP mechanisms like the Gaussian mechanism. In this work, we close this gap by providing the first high-probability convergence analysis for DP-Clipped-SGD with a fixed clipping level, applicable to both convex and non-convex smooth optimization under heavy-tailed noise, characterized by a bounded central $\alpha$-th moment assumption, $\alpha \in (1,2]$. Our results show that, with a fixed clipping level, the method converges to a neighborhood of the optimal solution with a faster rate than the existing ones. The neighborhood can be balanced against the noise introduced by DP, providing a refined trade-off between convergence speed and privacy guarantees. | http://arxiv.org/abs/2507.23512v1 |
|    34 | {"pass_filter":false,"exclude_reason":"purely theoretical without empirical validation","raw_score":0,"norm_score":0,"reason":"Excluded: purely theoretical without empirical validation"} | A Verifier Hierarchy | Maurits Kaptein | We investigate the trade-off between certificate length and verifier runtime. We prove a Verifier Trade-off Theorem showing that reducing the inherent verification time of a language from \(f(n)\) to \(g(n)\), where \(f(n) \ge g(n)\), requires certificates of length at least \(\Omega(\log(f(n) / g(n)))\). This theorem induces a natural hierarchy based on certificate complexity. We demonstrate its applicability to analyzing conjectured separations between complexity classes (e.g., \(\np\) and \(\exptime\)) and to studying natural problems such as string periodicity and rotation detection. Additionally, we provide perspectives on the \(\p\) vs. \(\np\) problem by relating it to the existence of sub-linear certificates. | http://arxiv.org/abs/2507.23504v1 |
|    35 | {"pass_filter":false,"exclude_reason":"Core features < 2","raw_score":0,"norm_score":0,"reason":"Excluded: Core features < 2"} | Directional Ensemble Aggregation for Actor-Critics | Nicklas Werge, Yi-Shan Wu, Bahareh Tasdighi, Melih Kandemir | Off-policy reinforcement learning in continuous control tasks depends critically on accurate $Q$-value estimates. Conservative aggregation over ensembles, such as taking the minimum, is commonly used to mitigate overestimation bias. However, these static rules are coarse, discard valuable information from the ensemble, and cannot adapt to task-specific needs or different learning regimes. We propose Directional Ensemble Aggregation (DEA), an aggregation method that adaptively combines $Q$-value estimates in actor-critic frameworks. DEA introduces two fully learnable directional parameters: one that modulates critic-side conservatism and another that guides actor-side policy exploration. Both parameters are learned using ensemble disagreement-weighted Bellman errors, which weight each sample solely by the direction of its Bellman error. This directional learning mechanism allows DEA to adjust conservatism and exploration in a data-driven way, adapting aggregation to both uncertainty levels and the phase of training. We evaluate DEA across continuous control benchmarks and learning regimes - from interactive to sample-efficient - and demonstrate its effectiveness over static ensemble strategies. | http://arxiv.org/abs/2507.23501v1 |
|    36 | {"pass_filter":false,"exclude_reason":"single-modality (pure text) and pure theoretical analysis without substantial empirical validation","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality pure text with no empirical validation"} | Incorporating structural uncertainty in causal decision making | Maurits Kaptein | Practitioners making decisions based on causal effects typically ignore structural uncertainty. We analyze when this uncertainty is consequential enough to warrant methodological solutions (Bayesian model averaging over competing causal structures). Focusing on bivariate relationships ($X \rightarrow Y$ vs. $X \leftarrow Y$), we establish that model averaging is beneficial when: (1) structural uncertainty is moderate to high, (2) causal effects differ substantially between structures, and (3) loss functions are sufficiently sensitive to the size of the causal effect. We prove optimality results of our suggested methodological solution under regularity conditions and demonstrate through simulations that modern causal discovery methods can provide, within limits, the necessary quantification. Our framework complements existing robust causal inference approaches by addressing a distinct source of uncertainty typically overlooked in practice. | http://arxiv.org/abs/2507.23495v1 |
|    37 | {"pass_filter":false,"exclude_reason":"single-modality (only text/medical data)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality (only text/medical data)"} | Explainable artificial intelligence model predicting the risk of   all-cause mortality in patients with type 2 diabetes mellitus | Olga Vershinina, Jacopo Sabbatinelli, Anna Rita Bonfigli, Dalila Colombaretti, Angelica Giuliani, Mikhail Krivonosov, Arseniy Trukhanov, Claudio Franceschi, Mikhail Ivanchenko, Fabiola Olivieri | Objective. Type 2 diabetes mellitus (T2DM) is a highly prevalent non-communicable chronic disease that substantially reduces life expectancy. Accurate estimation of all-cause mortality risk in T2DM patients is crucial for personalizing and optimizing treatment strategies. Research Design and Methods. This study analyzed a cohort of 554 patients (aged 40-87 years) with diagnosed T2DM over a maximum follow-up period of 16.8 years, during which 202 patients (36%) died. Key survival-associated features were identified, and multiple machine learning (ML) models were trained and validated to predict all-cause mortality risk. To improve model interpretability, Shapley additive explanations (SHAP) was applied to the best-performing model. Results. The extra survival trees (EST) model, incorporating ten key features, demonstrated the best predictive performance. The model achieved a C-statistic of 0.776, with the area under the receiver operating characteristic curve (AUC) values of 0.86, 0.80, 0.841, and 0.826 for 5-, 10-, 15-, and 16.8-year all-cause mortality predictions, respectively. The SHAP approach was employed to interpret the model's individual decision-making processes. Conclusions. The developed model exhibited strong predictive performance for mortality risk assessment. Its clinically interpretable outputs enable potential bedside application, improving the identification of high-risk patients and supporting timely treatment optimization. | http://arxiv.org/abs/2507.23491v1 |
|    38 | {"pass_filter":false,"exclude_reason":"single-modality (chest X-ray images only)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality (chest X-ray images only)"} | Machine learning and machine learned prediction in chest X-ray images | Shereiff Garrett, Abhinav Adhikari, Sarina Gautam, DaShawn Marquis Morris, Chandra Mani Adhikari | Machine learning and artificial intelligence are fast-growing fields of research in which data is used to train algorithms, learn patterns, and make predictions. This approach helps to solve seemingly intricate problems with significant accuracy without explicit programming by recognizing complex relationships in data. Taking an example of 5824 chest X-ray images, we implement two machine learning algorithms, namely, a baseline convolutional neural network (CNN) and a DenseNet-121, and present our analysis in making machine-learned predictions in predicting patients with ailments. Both baseline CNN and DenseNet-121 perform very well in the binary classification problem presented in this work. Gradient-weighted class activation mapping shows that DenseNet-121 correctly focuses on essential parts of the input chest X-ray images in its decision-making more than the baseline CNN. | http://arxiv.org/abs/2507.23455v1 |
|    39 | {"pass_filter":false,"exclude_reason":"single-modality time series anomaly detection","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality time series anomaly detection"} | Manifold-regularised Signature Kernel Large-Margin $\ell_p$-SVDD for   Multidimensional Time Series Anomaly Detection | Shervin Rahimzadeh Arashloo | We generalise the recently introduced large-margin $\ell_p$-SVDD approach to exploit the geometry of data distribution via manifold regularising and a signature kernel representation for time series anomaly detection. Specifically, we formulate a manifold-regularised variant of the $\ell_p$-SVDD method to encourage label smoothness on the underlying manifold to capture structural information for improved detection performance. Drawing on an existing Representer theorem, we then provide an effective optimisation technique for the proposed method and show that it can benefit from the signature kernel to capture time series complexities for anomaly detection.   We theoretically study the proposed approach using Rademacher complexities to analyse its generalisation performance and also provide an experimental assessment of the proposed method across various data sets to compare its performance against other methods. | http://arxiv.org/abs/2507.23449v1 |
|    40 | {"pass_filter":false,"exclude_reason":"single-modality aerodynamic shape optimization","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality aerodynamic shape optimization"} | Adjoint-Based Aerodynamic Shape Optimization with a Manifold Constraint   Learned by Diffusion Models | Long Chen, Emre Oezkaya, Jan Rottmayer, Nicolas R. Gauger, Zebang Shen, Yinyu Ye | We introduce an adjoint-based aerodynamic shape optimization framework that integrates a diffusion model trained on existing designs to learn a smooth manifold of aerodynamically viable shapes. This manifold is enforced as an equality constraint to the shape optimization problem. Central to our method is the computation of adjoint gradients of the design objectives (e.g., drag and lift) with respect to the manifold space. These gradients are derived by first computing shape derivatives with respect to conventional shape design parameters (e.g., Hicks-Henne parameters) and then backpropagating them through the diffusion model to its latent space via automatic differentiation. Our framework preserves mathematical rigor and can be integrated into existing adjoint-based design workflows with minimal modification. Demonstrated on extensive transonic RANS airfoil design cases using off-the-shelf and general-purpose nonlinear optimizers, our approach eliminates ad hoc parameter tuning and variable scaling, maintains robustness across initialization and optimizer choices, and achieves superior aerodynamic performance compared to conventional approaches. This work establishes how AI generated priors integrates effectively with adjoint methods to enable robust, high-fidelity aerodynamic shape optimization through automatic differentiation. | http://arxiv.org/abs/2507.23443v1 |
|    41 | {"pass_filter":false,"exclude_reason":"single-modality DNN accelerator design","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality DNN accelerator design"} | Coflex: Enhancing HW-NAS with Sparse Gaussian Processes for Efficient   and Scalable DNN Accelerator Design | Yinhui Ma, Tomomasa Yamasaki, Zhehui Wang, Tao Luo, Bo Wang | Hardware-Aware Neural Architecture Search (HW-NAS) is an efficient approach to automatically co-optimizing neural network performance and hardware energy efficiency, making it particularly useful for the development of Deep Neural Network accelerators on the edge. However, the extensive search space and high computational cost pose significant challenges to its practical adoption. To address these limitations, we propose Coflex, a novel HW-NAS framework that integrates the Sparse Gaussian Process (SGP) with multi-objective Bayesian optimization. By leveraging sparse inducing points, Coflex reduces the GP kernel complexity from cubic to near-linear with respect to the number of training samples, without compromising optimization performance. This enables scalable approximation of large-scale search space, substantially decreasing computational overhead while preserving high predictive accuracy. We evaluate the efficacy of Coflex across various benchmarks, focusing on accelerator-specific architecture. Our experi- mental results show that Coflex outperforms state-of-the-art methods in terms of network accuracy and Energy-Delay-Product, while achieving a computational speed-up ranging from 1.9x to 9.5x. | http://arxiv.org/abs/2507.23437v1 |
|    42 | {"pass_filter":false,"exclude_reason":"single-modality PDE modeling","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality PDE modeling"} | Merging Memory and Space: A Spatiotemporal State Space Neural Operator | Nodens F. Koren, Samuel Lanthaler | We propose the Spatiotemporal State Space Neural Operator (ST-SSM), a compact architecture for learning solution operators of time-dependent partial differential equations (PDEs). ST-SSM introduces a novel factorization of the spatial and temporal dimensions, using structured state-space models to independently model temporal evolution and spatial interactions. This design enables parameter efficiency and flexible modeling of long-range spatiotemporal dynamics. A theoretical connection is established between SSMs and neural operators, and a unified universality theorem is proved for the resulting class of architectures. Empirically, we demonstrate that our factorized formulation outperforms alternative schemes such as zigzag scanning and parallel independent processing on several PDE benchmarks, including 1D Burgers' equation, 1D Kuramoto-Sivashinsky equation, and 2D Navier-Stokes equations under varying physical conditions. Our model performs competitively with existing baselines while using significantly fewer parameters. In addition, our results reinforce previous findings on the benefits of temporal memory by showing improved performance under partial observability. Our results highlight the advantages of dimensionally factorized operator learning for efficient and generalizable PDE modeling, and put this approach on a firm theoretical footing. | http://arxiv.org/abs/2507.23428v1 |
|    43 | {"pass_filter":false,"exclude_reason":"single-modality (infrared spectroscopy only)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality (infrared spectroscopy only)"} | Detection of Adulteration in Coconut Milk using Infrared Spectroscopy   and Machine Learning | Mokhtar A. Al-Awadhi, Ratnadeep R. Deshmukh | In this paper, we propose a system for detecting adulteration in coconut milk, utilizing infrared spectroscopy. The machine learning-based proposed system comprises three phases: preprocessing, feature extraction, and classification. The first phase involves removing irrelevant data from coconut milk spectral signals. In the second phase, we employ the Linear Discriminant Analysis (LDA) algorithm for extracting the most discriminating features. In the third phase, we use the K-Nearest Neighbor (KNN) model to classify coconut milk samples into authentic or adulterated. We evaluate the performance of the proposed system using a public dataset comprising Fourier Transform Infrared (FTIR) spectral information of pure and contaminated coconut milk samples. Findings show that the proposed method successfully detects adulteration with a cross-validation accuracy of 93.33%. | http://arxiv.org/abs/2507.23418v1 |
|    44 | {"pass_filter":false,"exclude_reason":"single-modality (hyperspectral imaging only)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality (hyperspectral imaging only)"} | Honey Adulteration Detection using Hyperspectral Imaging and Machine   Learning | Mokhtar A. Al-Awadhi, Ratnadeep R. Deshmukh | This paper aims to develop a machine learning-based system for automatically detecting honey adulteration with sugar syrup, based on honey hyperspectral imaging data. First, the floral source of a honey sample is classified by a botanical origin identification subsystem. Then, the sugar syrup adulteration is identified, and its concentration is quantified by an adulteration detection subsystem. Both subsystems consist of two steps. The first step involves extracting relevant features from the honey sample using Linear Discriminant Analysis (LDA). In the second step, we utilize the K-Nearest Neighbors (KNN) model to classify the honey botanical origin in the first subsystem and identify the adulteration level in the second subsystem. We assess the proposed system performance on a public honey hyperspectral image dataset. The result indicates that the proposed system can detect adulteration in honey with an overall cross-validation accuracy of 96.39%, making it an appropriate alternative to the current chemical-based detection methods. | http://arxiv.org/abs/2507.23416v1 |
|    45 | {"pass_filter":false,"exclude_reason":"single-modality (mineral element profiles, no other modalities)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality (mineral element profiles, no other modalities)"} | A Machine Learning Approach for Honey Adulteration Detection using   Mineral Element Profiles | Mokhtar A. Al-Awadhi, Ratnadeep R. Deshmukh | This paper aims to develop a Machine Learning (ML)-based system for detecting honey adulteration utilizing honey mineral element profiles. The proposed system comprises two phases: preprocessing and classification. The preprocessing phase involves the treatment of missing-value attributes and normalization. In the classifica-tion phase, we use three supervised ML models: logistic regression, decision tree, and random forest, to dis-criminate between authentic and adulterated honey. To evaluate the performance of the ML models, we use a public dataset comprising measurements of mineral element content of authentic honey, sugar syrups, and adul-terated honey. Experimental findings show that mineral element content in honey provides robust discriminative information for detecting honey adulteration. Results also demonstrate that the random forest-based classifier outperforms other classifiers on this dataset, achieving the highest cross-validation accuracy of 98.37%. | http://arxiv.org/abs/2507.23412v1 |
|    46 | {"pass_filter":true,"exclude_reason":"","core_features":{"multi_modal":1,"large_scale":0,"unified_framework":1,"novel_paradigm":1},"plus_features":{"new_benchmark":0,"sota":0,"fusion_arch":1,"real_world_app":0,"reasoning_planning":0,"scaling_modalities":0,"open_source":0},"raw_score":7,"norm_score":7,"reason":"满足多模态、统一框架及新颖训练范式三大核心特征，并在融合架构上有创新。"} | AGA: An adaptive group alignment framework for structured medical   cross-modal representation learning | Wei Li, Xun Gong, Jiao Li, Xiaobin Sun | Learning medical visual representations from paired images and reports is a promising direction in representation learning. However, current vision-language pretraining methods in the medical domain often simplify clinical reports into single entities or fragmented tokens, ignoring their inherent structure. In addition, contrastive learning frameworks typically depend on large quantities of hard negative samples, which is impractical for small-scale medical datasets. To tackle these challenges, we propose Adaptive Grouped Alignment (AGA), a new framework that captures structured semantics from paired medical images and reports. AGA introduces a bidirectional grouping mechanism based on a sparse similarity matrix. For each image-report pair, we compute fine-grained similarities between text tokens and image patches. Each token selects its top-matching patches to form a visual group, and each patch selects its most related tokens to form a language group. To enable adaptive grouping, we design two threshold gating modules, called Language Grouped Threshold Gate and Vision Grouped Threshold Gate, which learn grouping thresholds dynamically. Group representations are computed as weighted averages based on similarity scores. To align each token with its group representation, we introduce an Instance Aware Group Alignment loss that operates within each image-text pair, removing the need for external negatives. Finally, a Bidirectional Cross-modal Grouped Alignment module is applied to enhance fine-grained alignment between visual and linguistic group representations. Extensive experiments on public and private datasets show that our method achieves strong performance on image-text retrieval and classification tasks under both fine-tuning and zero-shot settings. | http://arxiv.org/abs/2507.23402v1 |
|    47 | {"pass_filter":true,"exclude_reason":"","core_features":{"multi_modal":1,"large_scale":1,"unified_framework":0,"novel_paradigm":1},"plus_features":{"new_benchmark":0,"sota":1,"fusion_arch":0,"real_world_app":1,"reasoning_planning":0,"scaling_modalities":0,"open_source":0},"raw_score":8,"norm_score":8,"reason":"满足多模态、大规模模型及新颖训练范式三大核心特征，在真实应用和SOTA性能上表现突出。"} | Policy Learning from Large Vision-Language Model Feedback without Reward   Modeling | Tung M. Luu, Donghoon Lee, Younghwan Lee, Chang D. Yoo | Offline reinforcement learning (RL) provides a powerful framework for training robotic agents using pre-collected, suboptimal datasets, eliminating the need for costly, time-consuming, and potentially hazardous online interactions. This is particularly useful in safety-critical real-world applications, where online data collection is expensive and impractical. However, existing offline RL algorithms typically require reward labeled data, which introduces an additional bottleneck: reward function design is itself costly, labor-intensive, and requires significant domain expertise. In this paper, we introduce PLARE, a novel approach that leverages large vision-language models (VLMs) to provide guidance signals for agent training. Instead of relying on manually designed reward functions, PLARE queries a VLM for preference labels on pairs of visual trajectory segments based on a language task description. The policy is then trained directly from these preference labels using a supervised contrastive preference learning objective, bypassing the need to learn explicit reward models. Through extensive experiments on robotic manipulation tasks from the MetaWorld, PLARE achieves performance on par with or surpassing existing state-of-the-art VLM-based reward generation methods. Furthermore, we demonstrate the effectiveness of PLARE in real-world manipulation tasks with a physical robot, further validating its practical applicability. | http://arxiv.org/abs/2507.23391v1 |
|    48 | {"pass_filter":false,"exclude_reason":"single-modality (text only)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality (text only)"} | Causal Explanation of Concept Drift -- A Truly Actionable Approach | David Komnick, Kathrin Lammers, Barbara Hammer, Valerie Vaquet, Fabian Hinder | In a world that constantly changes, it is crucial to understand how those changes impact different systems, such as industrial manufacturing or critical infrastructure. Explaining critical changes, referred to as concept drift in the field of machine learning, is the first step towards enabling targeted interventions to avoid or correct model failures, as well as malfunctions and errors in the physical world. Therefore, in this work, we extend model-based drift explanations towards causal explanations, which increases the actionability of the provided explanations. We evaluate our explanation strategy on a number of use cases, demonstrating the practical usefulness of our framework, which isolates the causally relevant features impacted by concept drift and, thus, allows for targeted intervention. | http://arxiv.org/abs/2507.23389v1 |
|    49 | {"pass_filter":false,"exclude_reason":"single-modality (only LLM, no other modalities like vision, audio, etc.)","core_features":{"multi_modal":0,"large_scale":0,"unified_framework":0,"novel_paradigm":1},"plus_features":{},"raw_score":0,"norm_score":0,"reason":"Excluded: single-modality (only LLM, no other modalities)"} | SWE-Exp: Experience-Driven Software Issue Resolution | Silin Chen, Shaoxin Lin, Xiaodong Gu, Yuling Shi, Heng Lian, Longfei Yun, Dong Chen, Weiguo Sun, Lin Cao, Qianxiang Wang | Recent advances in large language model (LLM) agents have shown remarkable progress in software issue resolution, leveraging advanced techniques such as multi-agent collaboration and Monte Carlo Tree Search (MCTS). However, current agents act as memoryless explorers - treating each problem separately without retaining or reusing knowledge from previous repair experiences. This leads to redundant exploration of failed trajectories and missed chances to adapt successful issue resolution methods to similar problems. To address this problem, we introduce SWE-Exp, an experience - enhanced approach that distills concise and actionable experience from prior agent trajectories, enabling continuous learning across issues. Our method introduces a multi-faceted experience bank that captures both successful and failed repair attempts. Specifically, it extracts reusable issue resolution knowledge at different levels - from high-level problem comprehension to specific code changes. Experiments show that SWE-Exp achieves state-of-the-art resolution rate (41.6% Pass@1) on SWE-bench-Verified under open-source agent frameworks. Our approach establishes a new paradigm in which automated software engineering agents systematically accumulate and leverage repair expertise, fundamentally shifting from trial-and-error exploration to strategic, experience-driven issue resolution. | http://arxiv.org/abs/2507.23361v1 |
|    50 | {"pass_filter":false,"exclude_reason":"single-modality (pure text)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality (pure text)"} | Optimal Transport Learning: Balancing Value Optimization and Fairness in   Individualized Treatment Rules | Wenhai Cui, Xiaoting Ji, Wen Su, Xiaodong Yan, Xingqiu Zhao | Individualized treatment rules (ITRs) have gained significant attention due to their wide-ranging applications in fields such as precision medicine, ridesharing, and advertising recommendations. However, when ITRs are influenced by sensitive attributes such as race, gender, or age, they can lead to outcomes where certain groups are unfairly advantaged or disadvantaged. To address this gap, we propose a flexible approach based on the optimal transport theory, which is capable of transforming any optimal ITR into a fair ITR that ensures demographic parity. Recognizing the potential loss of value under fairness constraints, we introduce an ``improved trade-off ITR," designed to balance value optimization and fairness while accommodating varying levels of fairness through parameter adjustment. To maximize the value of the improved trade-off ITR under specific fairness levels, we propose a smoothed fairness constraint for estimating the adjustable parameter. Additionally, we establish a theoretical upper bound on the value loss for the improved trade-off ITR. We demonstrate performance of the proposed method through extensive simulation studies and application to the Next 36 entrepreneurial program dataset. | http://arxiv.org/abs/2507.23349v1 |
|    51 | {"pass_filter":false,"exclude_reason":"single-modality software issue resolution (pure text/code)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality software issue resolution (pure text/code)"} | SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution | Han Li, Yuling Shi, Shaoxin Lin, Xiaodong Gu, Heng Lian, Xin Wang, Yantao Jia, Tao Huang, Qianxiang Wang | Issue resolution has made remarkable progress thanks to the advanced reasoning capabilities of large language models (LLMs). Recently, agent-based frameworks such as SWE-agent have further advanced this progress by enabling autonomous, tool-using agents to tackle complex software engineering tasks. While existing agent-based issue resolution approaches are primarily based on agents' independent explorations, they often get stuck in local solutions and fail to identify issue patterns that span across different parts of the codebase. To address this limitation, we propose SWE-Debate, a competitive multi-agent debate framework that encourages diverse reasoning paths and achieves more consolidated issue localization. SWE-Debate first creates multiple fault propagation traces as localization proposals by traversing a code dependency graph. Then, it organizes a three-round debate among specialized agents, each embodying distinct reasoning perspectives along the fault propagation trace. This structured competition enables agents to collaboratively converge on a consolidated fix plan. Finally, this consolidated fix plan is integrated into an MCTS-based code modification agent for patch generation. Experiments on the SWE-bench benchmark show that SWE-Debate achieves new state-of-the-art results in open-source agent frameworks and outperforms baselines by a large margin. | http://arxiv.org/abs/2507.23348v1 |
|    52 | {"pass_filter":false,"exclude_reason":"core_features不足2项（无multi-modal、large_scale、unified_framework、novel_paradigm）","raw_score":0,"norm_score":0,"reason":"Excluded: core_features不足2项"} | Designing Dynamic Pricing for Bike-sharing Systems via Differentiable   Agent-based Simulation | Tatsuya Mitomi, Fumiyasu Makinoshima, Fumiya Makihara, Eigo Segawa | Bike-sharing systems are emerging in various cities as a new ecofriendly transportation system. In these systems, spatiotemporally varying user demands lead to imbalanced inventory at bicycle stations, resulting in additional relocation costs. Therefore, it is essential to manage user demand through optimal dynamic pricing for the system. However, optimal pricing design for such a system is challenging because the system involves users with diverse backgrounds and their probabilistic choices. To address this problem, we develop a differentiable agent-based simulation to rapidly design dynamic pricing in bike-sharing systems, achieving balanced bicycle inventory despite spatiotemporally heterogeneous trips and probabilistic user decisions. We first validate our approach against conventional methods through numerical experiments involving 25 bicycle stations and five time slots, yielding 100 parameters. Compared to the conventional methods, our approach obtains a more accurate solution with a 73% to 78% reduction in loss while achieving more than a 100-fold increase in convergence speed. We further validate our approach on a large-scale urban bike-sharing system scenario involving 289 bicycle stations, resulting in a total of 1156 parameters. Through simulations using the obtained pricing policies, we confirm that these policies can naturally induce balanced inventory without any manual relocation. Additionally, we find that the cost of discounts to induce the balanced inventory can be minimized by setting appropriate initial conditions. | http://arxiv.org/abs/2507.23344v1 |
|    53 | {"pass_filter":false,"exclude_reason":"core_features < 2","raw_score":0,"norm_score":0,"reason":"Excluded: core_features < 2"} | Scalable and Precise Patch Robustness Certification for Deep Learning   Models with Top-k Predictions | Qilin Zhou, Haipeng Wang, Zhengyuan Wei, W. K. Chan | Patch robustness certification is an emerging verification approach for defending against adversarial patch attacks with provable guarantees for deep learning systems. Certified recovery techniques guarantee the prediction of the sole true label of a certified sample. However, existing techniques, if applicable to top-k predictions, commonly conduct pairwise comparisons on those votes between labels, failing to certify the sole true label within the top k prediction labels precisely due to the inflation on the number of votes controlled by the attacker (i.e., attack budget); yet enumerating all combinations of vote allocation suffers from the combinatorial explosion problem. We propose CostCert, a novel, scalable, and precise voting-based certified recovery defender. CostCert verifies the true label of a sample within the top k predictions without pairwise comparisons and combinatorial explosion through a novel design: whether the attack budget on the sample is infeasible to cover the smallest total additional votes on top of the votes uncontrollable by the attacker to exclude the true labels from the top k prediction labels. Experiments show that CostCert significantly outperforms the current state-of-the-art defender PatchGuard, such as retaining up to 57.3% in certified accuracy when the patch size is 96, whereas PatchGuard has already dropped to zero. | http://arxiv.org/abs/2507.23335v1 |
|    54 | {"pass_filter":false,"exclude_reason":"single-modality text-only music QA","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality text-only music QA"} | MUST-RAG: MUSical Text Question Answering with Retrieval Augmented   Generation | Daeyong Kwon, SeungHeon Doh, Juhan Nam | Recent advancements in Large language models (LLMs) have demonstrated remarkable capabilities across diverse domains. While they exhibit strong zero-shot performance on various tasks, LLMs' effectiveness in music-related applications remains limited due to the relatively small proportion of music-specific knowledge in their training data. To address this limitation, we propose MusT-RAG, a comprehensive framework based on Retrieval Augmented Generation (RAG) to adapt general-purpose LLMs for text-only music question answering (MQA) tasks. RAG is a technique that provides external knowledge to LLMs by retrieving relevant context information when generating answers to questions. To optimize RAG for the music domain, we (1) propose MusWikiDB, a music-specialized vector database for the retrieval stage, and (2) utilizes context information during both inference and fine-tuning processes to effectively transform general-purpose LLMs into music-specific models. Our experiment demonstrates that MusT-RAG significantly outperforms traditional fine-tuning approaches in enhancing LLMs' music domain adaptation capabilities, showing consistent improvements across both in-domain and out-of-domain MQA benchmarks. Additionally, our MusWikiDB proves substantially more effective than general Wikipedia corpora, delivering superior performance and computational efficiency. | http://arxiv.org/abs/2507.23334v1 |
|    55 | {"pass_filter":true,"exclude_reason":"","core_features":{"multi_modal":0,"large_scale":1,"unified_framework":0,"novel_paradigm":1},"plus_features":{"new_benchmark":0,"sota":0,"fusion_arch":0,"real_world_app":0,"reasoning_planning":1,"scaling_modalities":0,"open_source":1},"raw_score":6,"norm_score":6.0,"reason":"通过硬门槛过滤，满足large_scale和novel_paradigm核心特征，且在推理任务优化和开源方面有优势。"} | Good Learners Think Their Thinking: Generative PRM Makes Large Reasoning   Model More Efficient Math Learner | Tao He, Rongchuan Mu, Lizi Liao, Yixin Cao, Ming Liu, Bing Qin | Large reasoning models (LRMs) have recently shown promise in solving complex math problems when optimized with Reinforcement Learning (RL). But conventional approaches rely on outcome-only rewards that provide sparse feedback, resulting in inefficient optimization process. In this work, we investigate the function of process reward models (PRMs) to accelerate the RL training for LRMs. We propose a novel intrinsic signal-driven generative process evaluation mechanism operating at the thought level to address major bottlenecks in RL-based training. Specifically, instead of requiring PRMs to know how to solve problems, our method uses intrinsic signals in solutions to judge stepwise correctness and aggregate contiguous correct/incorrect steps into coherent 'thought' units. This structured, thought-level rewards enable more reliable credit assignment by reducing ambiguity in step segmentation and alleviating reward hacking. We further introduce a capability-adaptive reward mechanism that dynamically balances exploration and exploitation based on the LRM's current proficiency, guiding learning without stifling creative trial-and-error. These innovations are integrated into a new off-policy RL algorithm, TP-GRPO, which extends grouped proximal optimization with process-based rewards and improves training efficiency. Experiments on 1.5B and 7B parameter LRMs demonstrate that our method achieves higher problem-solving accuracy with significantly fewer training samples than outcome-only reward baselines. The results validate that well-structured process rewards can substantially accelerate LRM optimization in math reasoning tasks. Code is available at https://github.com/cs-holder/tp_grpo. | http://arxiv.org/abs/2507.23317v1 |
|    56 | {"pass_filter":false,"exclude_reason":"single-modality image classification","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality image classification"} | Impact of Hyperparameter Optimization on the Accuracy of Lightweight   Deep Learning Models for Real-Time Image Classification | Vineet Kumar Rakesh, Soumya Mazumdar, Tapas Samanta, Sarbajit Pal, Amitabha Das | Lightweight convolutional and transformer-based models have become vital for real-time image classification in resource-constrained applications, such as embedded systems and edge devices. This work analyzes the influence of hyperparameter adjustment on the accuracy and convergence behavior of seven efficient deep learning architectures: EfficientNetV2-S, ConvNeXt-T, MobileViT v2 (XXS/XS/S), MobileNetV3-L, TinyViT-21M, and RepVGG-A2. All models are trained on the ImageNet-1K dataset under consistent training settings, with an emphasis on real-time practicality. An comprehensive ablation study is undertaken to separate the effect of critical hyperparameters, including learning rate schedules, batch sizes, input resolution, data augmentation, regularization approaches, and optimizer choice. To assess appropriateness for real-time applications, each model is assessed not only in terms of Top-1 and Top-5 classification accuracy, but also in terms of inference time, parameter count, model size, and frames-per-second (FPS) on a GPU-accelerated edge deployment simulation. Results demonstrate that cosine learning rate decay and adjustable batch size may greatly boost both accuracy and convergence speed, while keeping low latency and memory cost. Notably, RepVGG-A2 achieves over 80% Top-1 accuracy with efficient inference performance, offering a compelling balance between accuracy and deployment cost for VGG-style models. The results give practical guidance for constructing resource-efficient deep learning models appropriate for real-time image processing pipelines. All code and training logs are publicly accessible at https://github.com/VineetKumarRakesh/lcnn-opt. | http://arxiv.org/abs/2507.23315v1 |
|    57 | {"pass_filter":false,"exclude_reason":"single-modality (only text, Next Basket Prediction domain)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality text-based Next Basket Prediction"} | An Interpretable Data-Driven Unsupervised Approach for the Prevention of   Forgotten Items | Luca Corbucci, Javier Alejandro Borges Legrottaglie, Francesco Spinnato, Anna Monreale, Riccardo Guidotti | Accurately identifying items forgotten during a supermarket visit and providing clear, interpretable explanations for recommending them remains an underexplored problem within the Next Basket Prediction (NBP) domain. Existing NBP approaches typically only focus on forecasting future purchases, without explicitly addressing the detection of unintentionally omitted items. This gap is partly due to the scarcity of real-world datasets that allow for the reliable estimation of forgotten items. Furthermore, most current NBP methods rely on black-box models, which lack transparency and limit the ability to justify recommendations to end users. In this paper, we formally introduce the forgotten item prediction task and propose two novel interpretable-by-design algorithms. These methods are tailored to identify forgotten items while offering intuitive, human-understandable explanations. Experiments on a real-world retail dataset show our algorithms outperform state-of-the-art NBP baselines by 10-15% across multiple evaluation metrics. | http://arxiv.org/abs/2507.23303v1 |
|    58 | {"pass_filter":false,"exclude_reason":"single-modality (pure theoretical physics inference without multi-modal data)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality (pure theoretical physics inference without multi-modal data)"} | Simulation-based inference for Precision Neutrino Physics through Neural   Monte Carlo tuning | A. Gavrikov, A. Serafini, D. Dolzhikov, A. Garfagnini, M. Gonchar, M. Grassi, R. Brugnera, V. Cerrone, L. V. D'Auria, R. M. Guizzetti, L. Lastrucci, G. Andronico, V. Antonelli, A. Barresi, D. Basilico, M. Beretta, A. Bergnoli, M. Borghesi, A. Brigatti, R. Bruno, A. Budano, B. Caccianiga, A. Cammi, R. Caruso, D. Chiesa, C. Clementi, C. Coletta, S. Dusini, A. Fabbri, G. Felici, G. Ferrante, M. G. Giammarchi, N. Giudice, N. Guardone, F. Houria, C. Landini, I. Lippi, L. Loi, P. Lombardi, F. Mantovani, S. M. Mari, A. Martini, L. Miramonti, M. Montuschi, M. Nastasi, D. Orestano, F. Ortica, A. Paoloni, L. Pelicci, E. Percalli, F. Petrucci, E. Previtali, G. Ranucci, A. C. Re, B. Ricci, A. Romani, C. Sirignano, M. Sisti, L. Stanco, E. Stanescu Farilla, V. Strati, M. D. C Torri, C. Tuvè, C. Venettacci, G. Verde, L. Votano | Precise modeling of detector energy response is crucial for next-generation neutrino experiments which present computational challenges due to lack of analytical likelihoods. We propose a solution using neural likelihood estimation within the simulation-based inference framework. We develop two complementary neural density estimators that model likelihoods of calibration data: conditional normalizing flows and a transformer-based regressor. We adopt JUNO - a large neutrino experiment - as a case study. The energy response of JUNO depends on several parameters, all of which should be tuned, given their non-linear behavior and strong correlations in the calibration data. To this end, we integrate the modeled likelihoods with Bayesian nested sampling for parameter inference, achieving uncertainties limited only by statistics with near-zero systematic biases. The normalizing flows model enables unbinned likelihood analysis, while the transformer provides an efficient binned alternative. By providing both options, our framework offers flexibility to choose the most appropriate method for specific needs. Finally, our approach establishes a template for similar applications across experimental neutrino and broader particle physics. | http://arxiv.org/abs/2507.23297v1 |
|    59 | {"pass_filter":false,"exclude_reason":"single-modality sequence processing","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality sequence processing"} | SequenceLayers: Sequence Processing and Streaming Neural Networks Made   Easy | RJ Skerry-Ryan, Julian Salazar, Soroosh Mariooryad, David Kao, Daisy Stanton, Eric Battenberg, Matt Shannon, Ron J. Weiss, Robin Scheibler, Jonas Rothfuss, Tom Bagby | We introduce a neural network layer API and library for sequence modeling, designed for easy creation of sequence models that can be executed both layer-by-layer (e.g., teacher-forced training) and step-by-step (e.g., autoregressive sampling). To achieve this, layers define an explicit representation of their state over time (e.g., a Transformer KV cache, a convolution buffer, an RNN hidden state), and a step method that evolves that state, tested to give identical results to a stateless layer-wise invocation. This and other aspects of the SequenceLayers contract enables complex models to be immediately streamable, mitigates a wide range of common bugs arising in both streaming and parallel sequence processing, and can be implemented in any deep learning library. A composable and declarative API, along with a comprehensive suite of layers and combinators, streamlines the construction of production-scale models from simple streamable components while preserving strong correctness guarantees. Our current implementations of SequenceLayers (JAX, TensorFlow 2) are available at https://github.com/google/sequence-layers. | http://arxiv.org/abs/2507.23292v1 |
|    60 | {"pass_filter":false,"exclude_reason":"single-modality (pure text) and theoretical without empirical validation","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality (pure text) and theoretical without empirical validation"} | Evaluating the Dynamics of Membership Privacy in Deep Learning | Yuetian Chen, Zhiqi Wang, Nathalie Baracaldo, Swanand Ravindra Kadhe, Lei Yu | Membership inference attacks (MIAs) pose a critical threat to the privacy of training data in deep learning. Despite significant progress in attack methodologies, our understanding of when and how models encode membership information during training remains limited. This paper presents a dynamic analytical framework for dissecting and quantifying privacy leakage dynamics at the individual sample level. By tracking per-sample vulnerabilities on an FPR-TPR plane throughout training, our framework systematically measures how factors such as dataset complexity, model architecture, and optimizer choice influence the rate and severity at which samples become vulnerable. Crucially, we discover a robust correlation between a sample's intrinsic learning difficulty, and find that the privacy risk of samples highly vulnerable in the final trained model is largely determined early during training. Our results thus provide a deeper understanding of how privacy risks dynamically emerge during training, laying the groundwork for proactive, privacy-aware model training strategies. | http://arxiv.org/abs/2507.23291v1 |
|    61 | {"pass_filter":false,"exclude_reason":"single-modality (text-only, no other modalities mentioned)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality (text-only)"} | DynaSwarm: Dynamically Graph Structure Selection for LLM-based   Multi-agent System | Hui Yi Leong, Yuqing Wu | Current multi-agent systems (MAS) frameworks often rely on manually designed and static collaboration graph structures, limiting adaptability and performance. To address these limitations, we propose DynaSwarm, a dynamic framework that enhances LLM-based MAS through two key innovations: (1) an actor-critic reinforcement learning (A2C) mechanism to optimize graph structures with improved stability over prior RL methods, and (2) a dynamic graph selector that adaptively chooses the optimal graph structure for each input sample via parameter-efficient LLM fine-tuning. DynaSwarm eliminates the need for rigid, one-fits-all graph architectures, instead leveraging sample-specific idiosyncrasies to dynamically route queries through specialized agent networks. (c) We propose to fine-tune the demonstration retriever to fully exploit the power of in-context learning (ICL). Extensive experiments on question answering, mathematical reasoning, and coding tasks demonstrate that DynaSwarm consistently outperforms state-of-the-art single-agent and MAS baselines across multiple LLM backbones. Our findings highlight the importance of sample-aware structural flexibility in LLM MAS designs. | http://arxiv.org/abs/2507.23261v1 |
|    62 | {"pass_filter":false,"exclude_reason":"single-modality machine unlearning","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality machine unlearning"} | Efficient Machine Unlearning via Influence Approximation | Jiawei Liu, Chenwang Wu, Defu Lian, Enhong Chen | Due to growing privacy concerns, machine unlearning, which aims at enabling machine learning models to ``forget" specific training data, has received increasing attention. Among existing methods, influence-based unlearning has emerged as a prominent approach due to its ability to estimate the impact of individual training samples on model parameters without retraining. However, this approach suffers from prohibitive computational overhead arising from the necessity to compute the Hessian matrix and its inverse across all training samples and parameters, rendering it impractical for large-scale models and scenarios involving frequent data deletion requests. This highlights the difficulty of forgetting. Inspired by cognitive science, which suggests that memorizing is easier than forgetting, this paper establishes a theoretical link between memorizing (incremental learning) and forgetting (unlearning). This connection allows machine unlearning to be addressed from the perspective of incremental learning. Unlike the time-consuming Hessian computations in unlearning (forgetting), incremental learning (memorizing) typically relies on more efficient gradient optimization, which supports the aforementioned cognitive theory. Based on this connection, we introduce the Influence Approximation Unlearning (IAU) algorithm for efficient machine unlearning from the incremental perspective. Extensive empirical evaluations demonstrate that IAU achieves a superior balance among removal guarantee, unlearning efficiency, and comparable model utility, while outperforming state-of-the-art methods across diverse datasets and model architectures. Our code is available at https://github.com/Lolo1222/IAU. | http://arxiv.org/abs/2507.23257v1 |
|    63 | {"pass_filter":false,"exclude_reason":"single-modality NLP (Bengali-focused LLM evaluation)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality NLP (Bengali-focused LLM evaluation)"} | Evaluating LLMs' Multilingual Capabilities for Bengali: Benchmark   Creation and Performance Analysis | Shimanto Bhowmik, Tawsif Tashwar Dipto, Md Sazzad Islam, Sheryl Hsu, Tahsin Reasat | Bengali is an underrepresented language in NLP research. However, it remains a challenge due to its unique linguistic structure and computational constraints. In this work, we systematically investigate the challenges that hinder Bengali NLP performance by focusing on the absence of standardized evaluation benchmarks. We then evaluated 10 recent open source Large Language Models (LLMs) in 8 of the translated datasets and performed a comprehensive error analysis to pinpoint their primary failure modes. Our findings reveal consistent performance gaps for Bengali compared to English, particularly for smaller models and specific model families like Mistral. We also identified promising robustness in certain architectures, such as DeepSeek, that maintain more stable performance across languages. Our analysis reveals an inverse relationship between tokenization efficiency and LLM accuracy where models tend to perform worse when inputs are excessively tokenized, whereas more efficient \& concise tokenization results in improved performance. These findings highlight critical areas where current models fall short and underscore the need for improved dataset quality and evaluation methodologies tailored to multilingual contexts. This work will catalyze further research on NLP for underrepresented languages, helping to democratize access to advanced language technologies worldwide. The code and dataset used in this research is publicly available at https://github.com/BengaliAI/bn-llm-benchmark. | http://arxiv.org/abs/2507.23248v1 |
|    64 | {"pass_filter":false,"exclude_reason":"core_features不足2项（仅满足multi_modal）","raw_score":0,"norm_score":0,"reason":"Excluded: core_features不足2项（仅满足multi_modal）"} | Generalized Reinforcement Learning for Retriever-Specific Query Rewriter   with Unstructured Real-World Documents | Sungguk Cha, DongWook Kim, Taeseung Hahn, Mintae Kim, Youngsub Han, Byoung-Ki Jeon | Retrieval-Augmented Generation (RAG) systems rely heavily on effective query formulation to unlock external knowledge, yet optimizing queries for diverse, unstructured real-world documents remains a challenge. We introduce \textbf{RL-QR}, a reinforcement learning framework for retriever-specific query rewriting that eliminates the need for human-annotated datasets and extends applicability to both text-only and multi-modal databases. By synthesizing scenario-question pairs and leveraging Generalized Reward Policy Optimization (GRPO), RL-QR trains query rewriters tailored to specific retrievers, enhancing retrieval performance across varied domains. Experiments on industrial in-house data demonstrate significant improvements, with $\text{RL-QR}_{\text{multi-modal}}$ achieving an 11\% relative gain in NDCG@3 for multi-modal RAG and $\text{RL-QR}_{\text{lexical}}$ yielding a 9\% gain for lexical retrievers. However, challenges persist with semantic and hybrid retrievers, where rewriters failed to improve performance, likely due to training misalignments. Our findings highlight RL-QR's potential to revolutionize query optimization for RAG systems, offering a scalable, annotation-free solution for real-world retrieval tasks, while identifying avenues for further refinement in semantic retrieval contexts. | http://arxiv.org/abs/2507.23242v1 |
|    65 | {"pass_filter":false,"exclude_reason":"核心特征不足2项（仅满足large_scale，缺乏multi_modal等）","raw_score":0,"norm_score":0,"reason":"Excluded: core features insufficient (only large_scale, missing multi_modal)"} | Enabling Few-Shot Alzheimer's Disease Diagnosis on Tabular Biomarker   Data with LLMs | Sophie Kearney, Shu Yang, Zixuan Wen, Bojian Hou, Duy Duong-Tran, Tianlong Chen, Jason Moore, Marylyn Ritchie, Li Shen | Early and accurate diagnosis of Alzheimer's disease (AD), a complex neurodegenerative disorder, requires analysis of heterogeneous biomarkers (e.g., neuroimaging, genetic risk factors, cognitive tests, and cerebrospinal fluid proteins) typically represented in a tabular format. With flexible few-shot reasoning, multimodal integration, and natural-language-based interpretability, large language models (LLMs) offer unprecedented opportunities for prediction with structured biomedical data. We propose a novel framework called TAP-GPT, Tabular Alzheimer's Prediction GPT, that adapts TableGPT2, a multimodal tabular-specialized LLM originally developed for business intelligence tasks, for AD diagnosis using structured biomarker data with small sample sizes. Our approach constructs few-shot tabular prompts using in-context learning examples from structured biomedical data and finetunes TableGPT2 using the parameter-efficient qLoRA adaption for a clinical binary classification task of AD or cognitively normal (CN). The TAP-GPT framework harnesses the powerful tabular understanding ability of TableGPT2 and the encoded prior knowledge of LLMs to outperform more advanced general-purpose LLMs and a tabular foundation model (TFM) developed for prediction tasks. To our knowledge, this is the first application of LLMs to the prediction task using tabular biomarker data, paving the way for future LLM-driven multi-agent frameworks in biomedical informatics. | http://arxiv.org/abs/2507.23227v1 |
|    66 | {"pass_filter":false,"exclude_reason":"single-modality text","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality text"} | A Single Direction of Truth: An Observer Model's Linear Residual Probe   Exposes and Steers Contextual Hallucinations | Charles O'Neill, Slava Chalnev, Chi Chi Zhao, Max Kirkby, Mudith Jayasekara | Contextual hallucinations -- statements unsupported by given context -- remain a significant challenge in AI. We demonstrate a practical interpretability insight: a generator-agnostic observer model detects hallucinations via a single forward pass and a linear probe on its residual stream. This probe isolates a single, transferable linear direction separating hallucinated from faithful text, outperforming baselines by 5-27 points and showing robust mid-layer performance across Gemma-2 models (2B to 27B). Gradient-times-activation localises this signal to sparse, late-layer MLP activity. Critically, manipulating this direction causally steers generator hallucination rates, proving its actionability. Our results offer novel evidence of internal, low-dimensional hallucination tracking linked to specific MLP sub-circuits, exploitable for detection and mitigation. We release the 2000-example ContraTales benchmark for realistic assessment of such solutions. | http://arxiv.org/abs/2507.23221v1 |
|    67 | {"pass_filter":false,"exclude_reason":"single-modality text","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality text"} | Model Directions, Not Words: Mechanistic Topic Models Using Sparse   Autoencoders | Carolina Zheng, Nicolas Beltran-Velez, Sweta Karlekar, Claudia Shi, Achille Nazaret, Asif Mallik, Amir Feder, David M. Blei | Traditional topic models are effective at uncovering latent themes in large text collections. However, due to their reliance on bag-of-words representations, they struggle to capture semantically abstract features. While some neural variants use richer representations, they are similarly constrained by expressing topics as word lists, which limits their ability to articulate complex topics. We introduce Mechanistic Topic Models (MTMs), a class of topic models that operate on interpretable features learned by sparse autoencoders (SAEs). By defining topics over this semantically rich space, MTMs can reveal deeper conceptual themes with expressive feature descriptions. Moreover, uniquely among topic models, MTMs enable controllable text generation using topic-based steering vectors. To properly evaluate MTM topics against word-list-based approaches, we propose \textit{topic judge}, an LLM-based pairwise comparison evaluation framework. Across five datasets, MTMs match or exceed traditional and neural baselines on coherence metrics, are consistently preferred by topic judge, and enable effective steering of LLM outputs. | http://arxiv.org/abs/2507.23220v1 |
|    68 | {"pass_filter":true,"exclude_reason":"","core_features":{"multi_modal":1,"large_scale":1,"unified_framework":0,"novel_paradigm":0},"plus_features":{"new_benchmark":0,"sota":1,"fusion_arch":1,"real_world_app":0,"reasoning_planning":0,"scaling_modalities":0,"open_source":0},"raw_score":6,"norm_score":6,"reason":"满足多模态与大规模两大核心特征，并在SOTA性能和融合架构上有突出表现。"} | Zero-Shot Document Understanding using Pseudo Table of Contents-Guided   Retrieval-Augmented Generation | Hyeon Seong Jeong, Sangwoo Jo, Byeong Hyun Yoon, Yoonseok Heo, Haedong Jeong, Taehoon Kim | Understanding complex multimodal documents remains challenging due to their structural inconsistencies and limited training data availability. We introduce \textit{DocsRay}, a training-free document understanding system that integrates pseudo Table of Contents (TOC) generation with hierarchical Retrieval-Augmented Generation (RAG). Our approach leverages multimodal Large Language Models' (LLMs) native capabilities to seamlessly process documents containing diverse elements such as text, images, charts, and tables without requiring specialized models or additional training. DocsRay's framework synergistically combines three key techniques: (1) a semantic structuring module using prompt-based LLM interactions to generate a hierarchical pseudo-TOC, (2) zero-shot multimodal analysis that converts diverse document elements into unified, text-centric representations using the inherent capabilities of multimodal LLMs, and (3) an efficient two-stage hierarchical retrieval system that reduces retrieval complexity from $O(N)$ to $O(S + k_1 \cdot N_s)$. Evaluated on documents averaging 49.4 pages and 20,971 textual tokens, DocsRay reduced query latency from 3.89 to 2.12 seconds, achieving a 45% efficiency improvement. On the MMLongBench-Doc benchmark, DocsRay-Pro attains an accuracy of 64.7%, substantially surpassing previous state-of-the-art results. | http://arxiv.org/abs/2507.23217v1 |
|    69 | {"pass_filter":false,"exclude_reason":"core features < 2","raw_score":0,"norm_score":0,"reason":"Excluded: core features < 2"} | Not Just What, But When: Integrating Irregular Intervals to LLM for   Sequential Recommendation | Wei-Wei Du, Takuma Udagawa, Kei Tateno | Time intervals between purchasing items are a crucial factor in sequential recommendation tasks, whereas existing approaches focus on item sequences and often overlook by assuming the intervals between items are static. However, dynamic intervals serve as a dimension that describes user profiling on not only the history within a user but also different users with the same item history. In this work, we propose IntervalLLM, a novel framework that integrates interval information into LLM and incorporates the novel interval-infused attention to jointly consider information of items and intervals. Furthermore, unlike prior studies that address the cold-start scenario only from the perspectives of users and items, we introduce a new viewpoint: the interval perspective to serve as an additional metric for evaluating recommendation methods on the warm and cold scenarios. Extensive experiments on 3 benchmarks with both traditional- and LLM-based baselines demonstrate that our IntervalLLM achieves not only 4.4% improvements in average but also the best-performing warm and cold scenarios across all users, items, and the proposed interval perspectives. In addition, we observe that the cold scenario from the interval perspective experiences the most significant performance drop among all recommendation methods. This finding underscores the necessity of further research on interval-based cold challenges and our integration of interval information in the realm of sequential recommendation tasks. Our code is available here: https://github.com/sony/ds-research-code/tree/master/recsys25-IntervalLLM. | http://arxiv.org/abs/2507.23209v1 |
|    70 | {"pass_filter":false,"exclude_reason":"single-modality recommendation system","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality recommendation system"} | Are Recommenders Self-Aware? Label-Free Recommendation Performance   Estimation via Model Uncertainty | Jiayu Li, Ziyi Ye, Guohao Jian, Zhiqiang Guo, Weizhi Ma, Qingyao Ai, Min Zhang | Can a recommendation model be self-aware? This paper investigates the recommender's self-awareness by quantifying its uncertainty, which provides a label-free estimation of its performance. Such self-assessment can enable more informed understanding and decision-making before the recommender engages with any users. To this end, we propose an intuitive and effective method, probability-based List Distribution uncertainty (LiDu). LiDu measures uncertainty by determining the probability that a recommender will generate a certain ranking list based on the prediction distributions of individual items. We validate LiDu's ability to represent model self-awareness in two settings: (1) with a matrix factorization model on a synthetic dataset, and (2) with popular recommendation algorithms on real-world datasets. Experimental results show that LiDu is more correlated with recommendation performance than a series of label-free performance estimators. Additionally, LiDu provides valuable insights into the dynamic inner states of models throughout training and inference. This work establishes an empirical connection between recommendation uncertainty and performance, framing it as a step towards more transparent and self-evaluating recommender systems. | http://arxiv.org/abs/2507.23208v1 |
|    71 | {"pass_filter":true,"exclude_reason":"","core_features":{"multi_modal":0,"large_scale":1,"unified_framework":0,"novel_paradigm":1},"plus_features":{"new_benchmark":1,"sota":1,"fusion_arch":0,"real_world_app":1,"reasoning_planning":1,"scaling_modalities":0,"open_source":0},"raw_score":8,"norm_score":8,"reason":"满足大规模模型与新颖范式两大核心特征，提出新评估基准并刷新SOTA，面向真实硬件应用且含推理规划机制。"} | Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks | Jianghui Wang, Vinay Joshi, Saptarshi Majumder, Xu Chao, Bin Ding, Ziqiong Liu, Pratik Prabhanjan Brahma, Dong Li, Zicheng Liu, Emad Barsoum | The demand for AI-generated GPU kernels is rapidly growing, influenced by the need for scalable, hardware-optimized solutions in both industry and academia. As deep learning workloads grow in complexity and diversity, it is imperative to automate low-level kernel development to meet performance and productivity demands. Major cloud providers, semiconductor companies, and research institutions are now investing heavily in AI-driven code generation for GPUs, aiming to reduce manual optimization efforts while achieving near-expert performance on hardware like AMD MI300X. The Triton language, a Python-based DSL for GPU programming, has emerged as a popular target for such AI-generated kernels due to its balance of performance and ease-of-coding. In this work, we present an evaluation suite for Triton-based GPU kernels and GEAK (Generating Efficient AI-centric GPU Kernels)-a framework that leverages cutting-edge LLMs to generate performant Triton code specifically for AMD GPUs, including the AMD MI300X and MI250. GEAK leverages inference-time compute scaling to produce Triton-based GPU kernels using a reasoning loop adapted from Reflexion-style feedback mechanisms. On two evaluation benchmarks, GEAK significantly outperformed the baselines of directly prompting frontier LLMs as well as Reflexion-based generation pipelines by achieving correctness up to $63$% and execution speed up of up to $2.59$X. These results highlight the promise of GEAK-like agentic code generation for accelerating the adoption of diverse hardware platforms and democratizing access to expert-level kernel performance. | http://arxiv.org/abs/2507.23194v1 |
|    72 | {"pass_filter":false,"exclude_reason":"core_features < 2","raw_score":0,"norm_score":0,"reason":"Excluded: core_features < 2"} | NaN-Propagation: A Novel Method for Sparsity Detection in Black-Box   Computational Functions | Peter Sharpe | Sparsity detection in black-box functions enables significant computational speedups in gradient-based optimization through Jacobian compression, but existing finite-difference methods suffer from false negatives due to coincidental zero gradients. These false negatives can silently corrupt gradient calculations, leading to difficult-to-diagnose errors. We introduce NaN-propagation, which exploits the universal contamination property of IEEE 754 Not-a-Number floating-point values to trace input-output dependencies through floating-point numerical computations. By systematically contaminating inputs with NaN and observing which outputs become NaN, the method reconstructs conservative sparsity patterns that eliminate false negatives. We demonstrate the approach on an aerospace wing weight model, achieving a 1.52x speedup while detecting dozens of dependencies missed by conventional methods -- a significant improvement since gradient computation is the bottleneck in many optimization workflows. The technique leverages IEEE 754 compliance to work across programming languages and math libraries without modifying existing black-box codes. Advanced strategies including NaN payload encoding enable faster-than-linear time complexity, improving upon existing black-box sparsity detection methods. Practical algorithms are also proposed to mitigate challenges from branching code execution common in engineering applications. | http://arxiv.org/abs/2507.23186v1 |
|    73 | {"pass_filter":false,"exclude_reason":"single-modality (only vision)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality (only vision)"} | CNN-based solution for mango classification in agricultural environments | Beatriz Díaz Peón, Jorge Torres Gómez, Ariel Fajardo Márquez | This article exemplifies the design of a fruit detection and classification system using Convolutional   Neural Networks (CNN). The goal is to develop a system that automatically assesses fruit quality for   farm inventory management. Specifically, a method for mango fruit classification was developed using   image processing, ensuring both accuracy and efficiency. Resnet-18 was selected as the preliminary   architecture for classification, while a cascade detector was used for detection, balancing execution speed   and computational resource consumption. Detection and classification results were displayed through a   graphical interface developed in MatLab App Designer, streamlining system interaction. The integration   of convolutional neural networks and cascade detectors proffers a reliable solution for fruit classification   and detection, with potential applications in agricultural quality control. | http://arxiv.org/abs/2507.23174v1 |
|    74 | {"pass_filter":false,"exclude_reason":"purely theoretical with no empirical validation","raw_score":0,"norm_score":0,"reason":"Excluded: purely theoretical with no empirical validation"} | BAR Conjecture: the Feasibility of Inference Budget-Constrained LLM   Services with Authenticity and Reasoning | Jinan Zhou, Rajat Ghosh, Vaishnavi Bhargava, Debojyoti Dutta, Aryan Singhal | When designing LLM services, practitioners care about three key properties: inference-time budget, factual authenticity, and reasoning capacity. However, our analysis shows that no model can simultaneously optimize for all three. We formally prove this trade-off and propose a principled framework named The BAR Theorem for LLM-application design. | http://arxiv.org/abs/2507.23170v1 |
|    75 | {"pass_filter":false,"exclude_reason":"single-modality (only language, no other modalities)","raw_score":0,"norm_score":0,"reason":"Excluded: single-modality (only language, no other modalities)"} | LENS: Learning Ensemble Confidence from Neural States for Multi-LLM   Answer Integration | Jizhou Guo | Large Language Models (LLMs) have demonstrated impressive performance across various tasks, with different models excelling in distinct domains and specific abilities. Effectively combining the predictions of multiple LLMs is crucial for enhancing system robustness and performance. However, existing ensemble methods often rely on simple techniques like voting or logits ensembling, which overlook the varying confidence and reliability of models in different contexts. In this work, we propose LENS (Learning ENsemble confidence from Neural States), a novel approach that learns to estimate model confidence by analyzing internal representations. For each LLM, we train a lightweight linear confidence predictor that leverages layer-wise hidden states and normalized probabilities as inputs. This allows for more nuanced weighting of model predictions based on their context-dependent reliability. Our method does not require modifying the model parameters and requires negligible additional computation. Experimental results on multiple-choice and boolean question-answering tasks demonstrate that LENS outperforms traditional ensemble methods by a substantial margin. Our findings suggest that internal representations provide valuable signals for determining model confidence and can be effectively leveraged for ensemble learning. | http://arxiv.org/abs/2507.23167v1 |
