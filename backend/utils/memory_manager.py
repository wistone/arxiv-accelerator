#!/usr/bin/env python3
"""
å†…å­˜ç®¡ç†å·¥å…· - æ™ºèƒ½å†…å­˜ä¼˜åŒ–å’Œç›‘æ§

ä¸“ä¸ºRenderå…è´¹ç¯å¢ƒä¼˜åŒ–ï¼Œé¿å…å†…å­˜è¶…é™å¯¼è‡´çš„é‡å¯
"""

import gc
import sys
import time
import threading
from typing import Dict, Any, Optional
import psutil
import weakref


class MemoryManager:
    """æ™ºèƒ½å†…å­˜ç®¡ç†å™¨"""
    
    def __init__(self, max_memory_mb: int = 400):
        """
        åˆå§‹åŒ–å†…å­˜ç®¡ç†å™¨
        
        Args:
            max_memory_mb: æœ€å¤§å†…å­˜é™åˆ¶(MB)ï¼ŒRenderå…è´¹ç‰ˆçº¦512MB
        """
        self.max_memory_mb = max_memory_mb
        self.warning_threshold = max_memory_mb * 0.8  # 80%è­¦å‘Š
        self.critical_threshold = max_memory_mb * 0.95  # 95%ç´§æ€¥æ¸…ç†
        self.lock = threading.Lock()
        self.monitored_objects = {}
        
    def get_memory_usage(self) -> Dict[str, float]:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        process = psutil.Process()
        memory_info = process.memory_info()
        
        return {
            'rss_mb': memory_info.rss / 1024 / 1024,  # ç‰©ç†å†…å­˜
            'vms_mb': memory_info.vms / 1024 / 1024,  # è™šæ‹Ÿå†…å­˜
            'percent': process.memory_percent(),
            'available_mb': psutil.virtual_memory().available / 1024 / 1024
        }
    
    def check_memory_pressure(self) -> str:
        """æ£€æŸ¥å†…å­˜å‹åŠ›çŠ¶æ€"""
        usage = self.get_memory_usage()
        current_mb = usage['rss_mb']
        
        if current_mb > self.critical_threshold:
            return 'critical'
        elif current_mb > self.warning_threshold:
            return 'warning'
        else:
            return 'normal'
    
    def force_cleanup(self, level: str = 'normal'):
        """å¼ºåˆ¶å†…å­˜æ¸…ç†"""
        with self.lock:
            print(f"ğŸ§¹ [å†…å­˜ç®¡ç†] å¼€å§‹{level}çº§åˆ«æ¸…ç†...")
            before = self.get_memory_usage()
            
            if level in ['warning', 'critical']:
                # æ¸…ç†å…¨å±€ç¼“å­˜
                self._cleanup_global_caches()
                
            if level == 'critical':
                # ç´§æ€¥æ¸…ç†ï¼šå¼ºåˆ¶åƒåœ¾å›æ”¶
                for i in range(3):
                    collected = gc.collect()
                    print(f"ğŸ—‘ï¸ [å†…å­˜ç®¡ç†] åƒåœ¾å›æ”¶ç¬¬{i+1}æ¬¡: æ¸…ç†{collected}ä¸ªå¯¹è±¡")
            
            after = self.get_memory_usage()
            freed = before['rss_mb'] - after['rss_mb']
            print(f"ğŸ’¾ [å†…å­˜ç®¡ç†] æ¸…ç†å®Œæˆï¼Œé‡Šæ”¾: {freed:.1f}MBï¼Œå½“å‰: {after['rss_mb']:.1f}MB")
            
            return freed
    
    def _cleanup_global_caches(self):
        """æ¸…ç†å…¨å±€ç¼“å­˜"""
        try:
            # æ¸…ç†åˆ†æè¿›åº¦ç¼“å­˜
            import backend.server as server_module
            if hasattr(server_module, 'analysis_progress'):
                old_count = len(server_module.analysis_progress)
                # åªä¿ç•™æœ€è¿‘çš„ä»»åŠ¡
                current_time = time.time()
                cutoff_time = current_time - 3600  # 1å°æ—¶
                
                items_to_remove = []
                for task_id, progress in server_module.analysis_progress.items():
                    start_time = progress.get('start_time', 0)
                    if start_time < cutoff_time or progress.get('status') == 'completed':
                        items_to_remove.append(task_id)
                
                for task_id in items_to_remove:
                    del server_module.analysis_progress[task_id]
                
                print(f"ğŸ§¹ [ç¼“å­˜æ¸…ç†] analysis_progress: {old_count} -> {len(server_module.analysis_progress)}")
            
            # æ¸…ç†æœç´¢ç¼“å­˜
            if hasattr(server_module, '_search_cache'):
                server_module._search_cache.clear()
                print(f"ğŸ§¹ [ç¼“å­˜æ¸…ç†] search_cacheå·²æ¸…ç©º")
                
            # æ¸…ç†æœºæ„ç¼“å­˜  
            from backend.services.affiliation_service import clear_affiliation_cache
            clear_affiliation_cache()
            
        except Exception as e:
            print(f"âš ï¸ [ç¼“å­˜æ¸…ç†] éƒ¨åˆ†æ¸…ç†å¤±è´¥: {e}")


class LimitedCache:
    """é™åˆ¶å¤§å°çš„ç¼“å­˜"""
    
    def __init__(self, max_size: int = 100):
        """
        Args:
            max_size: æœ€å¤§ç¼“å­˜é¡¹æ•°
        """
        self.max_size = max_size
        self.cache = {}
        self.access_times = {}
        self.lock = threading.Lock()
    
    def get(self, key):
        """è·å–ç¼“å­˜é¡¹"""
        with self.lock:
            if key in self.cache:
                self.access_times[key] = time.time()
                return self.cache[key]
            return None
    
    def put(self, key, value):
        """è®¾ç½®ç¼“å­˜é¡¹"""
        with self.lock:
            if len(self.cache) >= self.max_size and key not in self.cache:
                # LRUæ¸…ç†
                oldest_key = min(self.access_times.keys(), 
                               key=lambda k: self.access_times[k])
                del self.cache[oldest_key]
                del self.access_times[oldest_key]
            
            self.cache[key] = value
            self.access_times[key] = time.time()
    
    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        with self.lock:
            self.cache.clear()
            self.access_times.clear()


class StreamBuffer:
    """æµå¼ç¼“å†²åŒº - æ›¿ä»£å…¨é‡å†…å­˜å­˜å‚¨"""
    
    def __init__(self, max_size: int = 10 * 1024 * 1024):  # 10MBé™åˆ¶
        """
        Args:
            max_size: æœ€å¤§ç¼“å†²åŒºå¤§å°(å­—èŠ‚)
        """
        self.max_size = max_size
        self.buffer = bytearray()
        self.overflow_file = None
        self.using_file = False
    
    def write(self, data: bytes):
        """å†™å…¥æ•°æ®"""
        if not self.using_file and len(self.buffer) + len(data) > self.max_size:
            # å†…å­˜ä¸è¶³ï¼Œåˆ‡æ¢åˆ°ä¸´æ—¶æ–‡ä»¶
            import tempfile
            self.overflow_file = tempfile.NamedTemporaryFile(mode='w+b', delete=True)
            self.overflow_file.write(self.buffer)
            self.overflow_file.write(data)
            self.buffer = bytearray()  # æ¸…ç†å†…å­˜
            self.using_file = True
            print(f"âš ï¸ [æµå¼ç¼“å†²] æ•°æ®è¿‡å¤§ï¼Œåˆ‡æ¢åˆ°ä¸´æ—¶æ–‡ä»¶å­˜å‚¨")
        elif self.using_file:
            self.overflow_file.write(data)
        else:
            self.buffer.extend(data)
    
    def get_content(self) -> bytes:
        """è·å–å®Œæ•´å†…å®¹"""
        if self.using_file:
            self.overflow_file.seek(0)
            content = self.overflow_file.read()
            return content
        else:
            return bytes(self.buffer)
    
    def __del__(self):
        """æ¸…ç†èµ„æº"""
        if self.overflow_file:
            self.overflow_file.close()


# å…¨å±€å†…å­˜ç®¡ç†å™¨å®ä¾‹
memory_manager = MemoryManager()


def monitor_memory(func):
    """å†…å­˜ç›‘æ§è£…é¥°å™¨"""
    def wrapper(*args, **kwargs):
        before = memory_manager.get_memory_usage()
        
        try:
            result = func(*args, **kwargs)
            return result
        finally:
            after = memory_manager.get_memory_usage()
            memory_used = after['rss_mb'] - before['rss_mb']
            
            if memory_used > 50:  # ä½¿ç”¨è¶…è¿‡50MBæ—¶è­¦å‘Š
                print(f"âš ï¸ [å†…å­˜ç›‘æ§] {func.__name__} ä½¿ç”¨äº† {memory_used:.1f}MB å†…å­˜")
            
            # è‡ªåŠ¨æ¸…ç†æ£€æŸ¥
            pressure = memory_manager.check_memory_pressure()
            if pressure == 'critical':
                print(f"ğŸš¨ [å†…å­˜ç›‘æ§] å†…å­˜å‹åŠ›è¿‡é«˜ï¼Œæ‰§è¡Œç´§æ€¥æ¸…ç†")
                memory_manager.force_cleanup('critical')
            elif pressure == 'warning':
                print(f"âš ï¸ [å†…å­˜ç›‘æ§] å†…å­˜ä½¿ç”¨åé«˜ï¼Œæ‰§è¡Œé¢„é˜²æ€§æ¸…ç†")
                memory_manager.force_cleanup('warning')
    
    return wrapper