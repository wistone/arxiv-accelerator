#!/usr/bin/env python3
"""
å¹¶å‘è®ºæ–‡åˆ†ææœåŠ¡

æä¾›å¤šçº¿ç¨‹å¹¶å‘çš„è®ºæ–‡åˆ†æåŠŸèƒ½ï¼Œæ˜¾è‘—æå‡åˆ†æé€Ÿåº¦
"""

import json
import time
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, Any, List, Optional, Callable

from backend.services.analysis_service import analyze_paper
from backend.services.affiliation_service import get_author_affiliations
from backend.clients.ai_client import DoubaoClient
from backend.db import repo as db_repo


class ConcurrentAnalysisService:
    """å¹¶å‘åˆ†ææœåŠ¡"""
    
    def __init__(self, max_workers: int = 5):
        """
        åˆå§‹åŒ–å¹¶å‘åˆ†ææœåŠ¡
        
        Args:
            max_workers: æœ€å¤§å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°
        """
        self.max_workers = max_workers
        self.progress_lock = threading.Lock()
        
    def analyze_papers_concurrent(
        self,
        task_id: str,
        pending_papers: List[Dict],
        prompt_id: str,
        system_prompt: str,
        progress_tracker: Dict[str, Any],
        update_progress_callback: Optional[Callable] = None
    ) -> Dict[str, Any]:
        """
        å¹¶å‘åˆ†æè®ºæ–‡åˆ—è¡¨
        
        Args:
            task_id: ä»»åŠ¡ID
            pending_papers: å¾…åˆ†æè®ºæ–‡åˆ—è¡¨
            prompt_id: æç¤ºè¯ID
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            progress_tracker: è¿›åº¦è·Ÿè¸ªå™¨
            update_progress_callback: è¿›åº¦æ›´æ–°å›è°ƒå‡½æ•°
            
        Returns:
            Dict: åˆ†æç»“æœç»Ÿè®¡
        """
        total_papers = len(pending_papers)
        completed_count = 0
        success_count = 0
        error_count = 0
        
        # åˆå§‹åŒ–è¿›åº¦
        with self.progress_lock:
            progress_tracker[task_id].update({
                'total': total_papers,
                'current': 0,
                'status': 'processing',
                'concurrent_workers': self.max_workers,
                'completed_papers': [],
                'processing_papers': []
            })
        
        print(f"ğŸš€ [å¹¶å‘åˆ†æ] å¯åŠ¨ {self.max_workers} è·¯å¹¶å‘åˆ†æï¼Œæ€»è®¡ {total_papers} ç¯‡è®ºæ–‡")
        
        def analyze_single_paper(paper_data: Dict) -> Dict[str, Any]:
            """åˆ†æå•ç¯‡è®ºæ–‡çš„å·¥ä½œå‡½æ•°"""
            thread_id = threading.current_thread().ident
            paper_id = paper_data['paper_id']
            start_time = time.time()
            
            # æ›´æ–°æ­£åœ¨å¤„ç†çš„è®ºæ–‡åˆ—è¡¨
            with self.progress_lock:
                progress_tracker[task_id]['processing_papers'].append({
                    'paper_id': paper_id,
                    'title': paper_data.get('title', '')[:50] + '...',
                    'thread_id': thread_id,
                    'start_time': start_time
                })
            
            try:
                # åˆ›å»ºç‹¬ç«‹çš„AIå®¢æˆ·ç«¯å®ä¾‹ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
                client = DoubaoClient()
                
                # 1. æ‰§è¡Œè®ºæ–‡åˆ†æ
                print(f"ğŸ” [çº¿ç¨‹-{thread_id}] å¼€å§‹åˆ†æè®ºæ–‡: {paper_data.get('title', '')[:30]}...")
                
                result = analyze_paper(
                    client, 
                    system_prompt, 
                    paper_data.get('title', ''), 
                    paper_data.get('abstract', '')
                )
                
                # è§£æåˆ†æç»“æœ
                try:
                    analysis_result = json.loads(result)
                except Exception:
                    analysis_result = {'raw': result}
                
                # 2. ä¿å­˜åˆ†æç»“æœåˆ°æ•°æ®åº“
                db_repo.insert_analysis_result(
                    paper_id=paper_id,
                    prompt_id=prompt_id,
                    analysis_json=analysis_result,
                    created_by=None,
                )
                
                # 3. å¦‚æœé€šè¿‡ç­›é€‰ä¸”ç¼ºå°‘æœºæ„ä¿¡æ¯ï¼Œè·å–ä½œè€…æœºæ„
                pass_filter = bool(analysis_result.get('pass_filter', False))
                has_affiliation = bool(paper_data.get('author_affiliation'))
                
                if pass_filter and not has_affiliation and paper_data.get('link'):
                    print(f"ğŸ›ï¸ [çº¿ç¨‹-{thread_id}] è®ºæ–‡é€šè¿‡ç­›é€‰ï¼Œå¼€å§‹è·å–æœºæ„ä¿¡æ¯...")
                    
                    try:
                        # å®šä¹‰è¿›åº¦å›è°ƒ
                        def affiliation_progress(message):
                            # è¿™é‡Œå¯ä»¥æ›´æ–°å…·ä½“è®ºæ–‡çš„æœºæ„è·å–è¿›åº¦
                            pass
                        
                        affiliations = get_author_affiliations(
                            paper_data['link'], 
                            progress_callback=affiliation_progress
                        )
                        
                        if affiliations:
                            aff_json = json.dumps(affiliations, ensure_ascii=False)
                            db_repo.update_paper_author_affiliation(paper_id, aff_json)
                            print(f"âœ… [çº¿ç¨‹-{thread_id}] æœºæ„ä¿¡æ¯æ›´æ–°å®Œæˆ: {len(affiliations)} ä¸ªæœºæ„")
                        
                    except Exception as aff_error:
                        print(f"âš ï¸ [çº¿ç¨‹-{thread_id}] æœºæ„ä¿¡æ¯è·å–å¤±è´¥: {aff_error}")
                
                elapsed_time = time.time() - start_time
                print(f"âœ… [çº¿ç¨‹-{thread_id}] è®ºæ–‡åˆ†æå®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f}s")
                
                return {
                    'paper_id': paper_id,
                    'success': True,
                    'result': analysis_result,
                    'elapsed_time': elapsed_time,
                    'thread_id': thread_id,
                    'pass_filter': pass_filter,
                    'has_affiliation': not has_affiliation and pass_filter,
                    # åªä¿ç•™æ ‡é¢˜ç”¨äºæ˜¾ç¤º
                    'title': paper_data.get('title', '')
                }
                
            except Exception as e:
                elapsed_time = time.time() - start_time
                print(f"âŒ [çº¿ç¨‹-{thread_id}] è®ºæ–‡åˆ†æå¤±è´¥: {e}, è€—æ—¶: {elapsed_time:.2f}s")
                
                return {
                    'paper_id': paper_id,
                    'success': False,
                    'error': str(e),
                    'elapsed_time': elapsed_time,
                    'thread_id': thread_id,
                    # åªä¿ç•™æ ‡é¢˜ç”¨äºæ˜¾ç¤º
                    'title': paper_data.get('title', '')
                }
            
            finally:
                # ä»æ­£åœ¨å¤„ç†åˆ—è¡¨ä¸­ç§»é™¤
                with self.progress_lock:
                    progress_tracker[task_id]['processing_papers'] = [
                        p for p in progress_tracker[task_id]['processing_papers'] 
                        if p['paper_id'] != paper_id
                    ]
        
        # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œå¹¶å‘åˆ†æ
        overall_start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_paper = {
                executor.submit(analyze_single_paper, paper): paper 
                for paper in pending_papers
            }
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_paper):
                paper = future_to_paper[future]
                completed_count += 1
                
                try:
                    result = future.result()
                    
                    if result['success']:
                        success_count += 1
                    else:
                        error_count += 1
                    
                    # æ›´æ–°è¿›åº¦
                    with self.progress_lock:
                        progress_tracker[task_id].update({
                            'current': completed_count,
                            'success_count': success_count,
                            'error_count': error_count,
                            'last_completed_paper': {
                                'title': paper.get('title', '')[:50],
                                'success': result['success'],
                                'elapsed_time': result['elapsed_time'],
                                'thread_id': result.get('thread_id')
                            }
                        })
                        
                        # æ·»åŠ åˆ°å·²å®Œæˆåˆ—è¡¨
                        progress_tracker[task_id]['completed_papers'].append(result)
                    
                    # è°ƒç”¨è¿›åº¦æ›´æ–°å›è°ƒ
                    if update_progress_callback:
                        update_progress_callback(task_id, completed_count, total_papers)
                        
                    print(f"ğŸ“Š [å¹¶å‘åˆ†æ] è¿›åº¦: {completed_count}/{total_papers} "
                          f"(æˆåŠŸ:{success_count}, å¤±è´¥:{error_count})")
                    
                except Exception as e:
                    error_count += 1
                    print(f"âŒ [å¹¶å‘åˆ†æ] ä»»åŠ¡ç»“æœå¤„ç†å¤±è´¥: {e}")
        
        # åˆ†æå®Œæˆ
        total_elapsed_time = time.time() - overall_start_time
        
        final_stats = {
            'total_papers': total_papers,
            'success_count': success_count,
            'error_count': error_count,
            'total_elapsed_time': total_elapsed_time,
            'average_time_per_paper': total_elapsed_time / total_papers if total_papers > 0 else 0,
            'concurrent_workers': self.max_workers
        }
        
        with self.progress_lock:
            progress_tracker[task_id].update({
                'status': 'completed',
                'final_stats': final_stats
            })
        
        print(f"ğŸ‰ [å¹¶å‘åˆ†æ] å…¨éƒ¨å®Œæˆï¼æ€»è€—æ—¶: {total_elapsed_time:.2f}s, "
              f"å¹³å‡æ¯ç¯‡: {final_stats['average_time_per_paper']:.2f}s, "
              f"æˆåŠŸ:{success_count}, å¤±è´¥:{error_count}")
        
        return final_stats


# å…¨å±€å®ä¾‹
_concurrent_service_1 = ConcurrentAnalysisService(max_workers=1)  # ä¸²è¡Œå¯¹ç…§ç»„
_concurrent_service_5 = ConcurrentAnalysisService(max_workers=5)  # 5è·¯å¹¶å‘


def get_concurrent_service(workers: int = 5) -> ConcurrentAnalysisService:
    """è·å–å¹¶å‘åˆ†ææœåŠ¡å®ä¾‹"""
    if workers == 1:
        return _concurrent_service_1
    elif workers == 5:
        return _concurrent_service_5
    else:
        return ConcurrentAnalysisService(max_workers=workers)


def run_performance_comparison(
    task_id: str,
    pending_papers: List[Dict],
    prompt_id: str,
    system_prompt: str,
    progress_tracker: Dict[str, Any],
    test_count: int = 10
) -> Dict[str, Any]:
    """
    è¿è¡Œæ€§èƒ½å¯¹æ¯”æµ‹è¯•
    
    Args:
        task_id: ä»»åŠ¡ID  
        pending_papers: å¾…åˆ†æè®ºæ–‡åˆ—è¡¨
        prompt_id: æç¤ºè¯ID
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        progress_tracker: è¿›åº¦è·Ÿè¸ªå™¨
        test_count: æµ‹è¯•è®ºæ–‡æ•°é‡
        
    Returns:
        Dict: æ€§èƒ½å¯¹æ¯”ç»“æœ
    """
    test_papers = pending_papers[:test_count]
    
    print(f"ğŸ§ª [æ€§èƒ½å¯¹æ¯”] å¼€å§‹æµ‹è¯• {test_count} ç¯‡è®ºæ–‡çš„æ€§èƒ½å¯¹æ¯”...")
    
    # 1è·¯ä¸²è¡Œæµ‹è¯•
    print("ğŸ“Š [æ€§èƒ½å¯¹æ¯”] å¼€å§‹1è·¯ä¸²è¡Œæµ‹è¯•...")
    serial_start = time.time()
    
    serial_service = get_concurrent_service(workers=1)
    serial_task_id = f"{task_id}_serial"
    progress_tracker[serial_task_id] = {}
    
    serial_result = serial_service.analyze_papers_concurrent(
        serial_task_id, test_papers, prompt_id, system_prompt, progress_tracker
    )
    serial_time = time.time() - serial_start
    
    # 5è·¯å¹¶å‘æµ‹è¯•  
    print("ğŸ“Š [æ€§èƒ½å¯¹æ¯”] å¼€å§‹5è·¯å¹¶å‘æµ‹è¯•...")
    concurrent_start = time.time()
    
    concurrent_service = get_concurrent_service(workers=5)
    concurrent_task_id = f"{task_id}_concurrent"
    progress_tracker[concurrent_task_id] = {}
    
    concurrent_result = concurrent_service.analyze_papers_concurrent(
        concurrent_task_id, test_papers, prompt_id, system_prompt, progress_tracker
    )
    concurrent_time = time.time() - concurrent_start
    
    # è®¡ç®—æ€§èƒ½æå‡
    speedup_ratio = serial_time / concurrent_time if concurrent_time > 0 else 0
    time_saved = serial_time - concurrent_time
    
    comparison_result = {
        'test_papers_count': test_count,
        'serial_result': {
            'total_time': serial_time,
            'success_count': serial_result['success_count'],
            'error_count': serial_result['error_count'],
            'avg_time_per_paper': serial_time / test_count
        },
        'concurrent_result': {
            'total_time': concurrent_time,
            'success_count': concurrent_result['success_count'], 
            'error_count': concurrent_result['error_count'],
            'avg_time_per_paper': concurrent_time / test_count,
            'workers': 5
        },
        'performance_gain': {
            'speedup_ratio': speedup_ratio,
            'time_saved_seconds': time_saved,
            'time_saved_percentage': (time_saved / serial_time * 100) if serial_time > 0 else 0
        }
    }
    
    print(f"ğŸ¯ [æ€§èƒ½å¯¹æ¯”] ç»“æœæ€»ç»“:")
    print(f"   ğŸ“ˆ 1è·¯ä¸²è¡Œ: {serial_time:.1f}s, å¹³å‡æ¯ç¯‡: {serial_time/test_count:.1f}s")
    print(f"   ğŸš€ 5è·¯å¹¶å‘: {concurrent_time:.1f}s, å¹³å‡æ¯ç¯‡: {concurrent_time/test_count:.1f}s")
    print(f"   âš¡ æ€§èƒ½æå‡: {speedup_ratio:.1f}x, èŠ‚çœæ—¶é—´: {time_saved:.1f}s ({time_saved/serial_time*100:.1f}%)")
    
    return comparison_result
